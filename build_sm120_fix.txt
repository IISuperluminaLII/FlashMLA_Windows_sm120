Applying SM120 Blackwell Workstation Fixes based on community solutions...

Step 1: Setting environment variables for SM120 build

Step 2: Build configuration for SM120
- CUDA architecture: 12.0 (SM120)
- Cluster shape forced to 1x1x1 (no multicast on GeForce)
- TMA/TMEM enabled (Blackwell has 4th gen tensor cores)
- Using CUTLASS with SM120 support

Build flags:
FLASH_MLA_DISABLE_SM100=0
FLASH_MLA_DISABLE_SM90=1
FLASH_MLA_SM120_DISABLE_BWD=0
ENABLE_SCALED_MM_SM120=1
TORCH_CUDA_ARCH_LIST=12.0

Step 3: Running build with SM120 configuration
Excluding SM90 source files (disabled)
Including backward kernel (SM120 backward enabled)
Including SM100-specific decode/sparse files
Training kernels (fwd/bwd): ALWAYS included (support SM100a + SM120)
Compiling using NVCC 12.9
Adding sm_120 (Blackwell workstation) support with PTX fallback
running clean
removing 'build\temp.win-amd64-cpython-312' (and everything under it)
removing 'build\lib.win-amd64-cpython-312' (and everything under it)
'build\bdist.win-amd64' does not exist -- can't clean it
'build\scripts-3.12' does not exist -- can't clean it
removing 'build'
Excluding SM90 source files (disabled)
Including backward kernel (SM120 backward enabled)
Including SM100-specific decode/sparse files
Training kernels (fwd/bwd): ALWAYS included (support SM100a + SM120)
Compiling using NVCC 12.9
Adding sm_120 (Blackwell workstation) support with PTX fallback
running build_ext
W1029 22:54:40.326000 7000 site-packages\torch\utils\cpp_extension.py:480] Error checking compiler version for cl: [WinError 2] The system cannot find the file specified
W1029 22:54:40.333000 7000 site-packages\torch\utils\cpp_extension.py:521] The detected CUDA version (12.9) has a minor version mismatch with the version that was used to compile PyTorch (12.8). Most likely this shouldn't be a problem.
building 'flash_mla.cuda' extension
creating C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc
creating C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\decode\sparse_fp8
creating C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\dense
creating C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\sparse
creating C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\smxx
W1029 22:54:41.979000 7000 site-packages\torch\utils\cpp_extension.py:480] Error checking compiler version for cl: [WinError 2] The system cannot find the file specified
C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\setuptools\_distutils\_msvccompiler.py:12: UserWarning: _get_vc_env is private; find an alternative (pypa/distutils#340)
  warnings.warn(
[1/7] C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin\nvcc --generate-dependencies-with-compile --dependency-output C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\dense\fmha_cutlass_bwd_sm100.obj.d -std=c++17 -Xcompiler /MD -Xcompiler /wd4819 -Xcompiler /wd4251 -Xcompiler /wd4244 -Xcompiler /wd4267 -Xcompiler /wd4275 -Xcompiler /wd4018 -Xcompiler /wd4190 -Xcompiler /wd4624 -Xcompiler /wd4067 -Xcompiler /wd4068 -Xcompiler /EHsc --use-local-env -Xcudafe --diag_suppress=base_class_has_different_dll_interface -Xcudafe --diag_suppress=field_without_dll_interface -Xcudafe --diag_suppress=dll_interface_conflict_none_assumed -Xcudafe --diag_suppress=dll_interface_conflict_dllexport_assumed -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm90 -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\include -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\tools\util\include "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include\torch\csrc\api\include" "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.44.35207\include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Auxiliary\VS\include" "-IC:\Program Files (x86)\Windows Kits\10\include\10.0.26100.0\ucrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\um" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\shared" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\winrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\cppwinrt" "-IC:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um" -c C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_bwd_sm100.cu -o C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\dense\fmha_cutlass_bwd_sm100.obj -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -include msvc_compat.h -O3 -std=c++17 -DNDEBUG -D_USE_MATH_DEFINES -Wno-deprecated-declarations -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v,--register-usage-level=10 -Xcompiler /Zc:__cplusplus -Xcompiler /permissive- -Xcompiler /Zc:__cplusplus -DFLASH_MLA_DISABLE_SM90 -gencode arch=compute_100a,code=sm_100a -gencode arch=compute_100a,code=compute_100a -gencode arch=compute_120,code=sm_120 -gencode arch=compute_120,code=compute_120 --threads 32 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=cuda
FAILED: [code=4294967295] C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/build/temp.win-amd64-cpython-312/Release/csrc/sm100/prefill/dense/fmha_cutlass_bwd_sm100.obj 
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin\nvcc --generate-dependencies-with-compile --dependency-output C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\dense\fmha_cutlass_bwd_sm100.obj.d -std=c++17 -Xcompiler /MD -Xcompiler /wd4819 -Xcompiler /wd4251 -Xcompiler /wd4244 -Xcompiler /wd4267 -Xcompiler /wd4275 -Xcompiler /wd4018 -Xcompiler /wd4190 -Xcompiler /wd4624 -Xcompiler /wd4067 -Xcompiler /wd4068 -Xcompiler /EHsc --use-local-env -Xcudafe --diag_suppress=base_class_has_different_dll_interface -Xcudafe --diag_suppress=field_without_dll_interface -Xcudafe --diag_suppress=dll_interface_conflict_none_assumed -Xcudafe --diag_suppress=dll_interface_conflict_dllexport_assumed -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm90 -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\include -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\tools\util\include "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include\torch\csrc\api\include" "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.44.35207\include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Auxiliary\VS\include" "-IC:\Program Files (x86)\Windows Kits\10\include\10.0.26100.0\ucrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\um" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\shared" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\winrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\cppwinrt" "-IC:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um" -c C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_bwd_sm100.cu -o C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\dense\fmha_cutlass_bwd_sm100.obj -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -include msvc_compat.h -O3 -std=c++17 -DNDEBUG -D_USE_MATH_DEFINES -Wno-deprecated-declarations -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v,--register-usage-level=10 -Xcompiler /Zc:__cplusplus -Xcompiler /permissive- -Xcompiler /Zc:__cplusplus -DFLASH_MLA_DISABLE_SM90 -gencode arch=compute_100a,code=sm_100a -gencode arch=compute_100a,code=compute_100a -gencode arch=compute_120,code=sm_120 -gencode arch=compute_120,code=compute_120 --threads 32 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=cuda
fmha_cutlass_bwd_sm100.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
fmha_cutlass_bwd_sm100.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
fmha_cutlass_bwd_sm100.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
fmha_cutlass_bwd_sm100.cu
C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device\../kernel/sm100_fmha_bwd_kernel_tma_warpspecialized.hpp(82): fatal error C1189: #error:  "SM120 backward pass is currently disabled. UniversalCopy implementation required for both forward and backward before re-enabling. See SM120_UNIVERSAL_COPY_PLAN.md"
[2/7] C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin\nvcc --generate-dependencies-with-compile --dependency-output C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\smxx\get_mla_metadata.obj.d -std=c++17 -Xcompiler /MD -Xcompiler /wd4819 -Xcompiler /wd4251 -Xcompiler /wd4244 -Xcompiler /wd4267 -Xcompiler /wd4275 -Xcompiler /wd4018 -Xcompiler /wd4190 -Xcompiler /wd4624 -Xcompiler /wd4067 -Xcompiler /wd4068 -Xcompiler /EHsc --use-local-env -Xcudafe --diag_suppress=base_class_has_different_dll_interface -Xcudafe --diag_suppress=field_without_dll_interface -Xcudafe --diag_suppress=dll_interface_conflict_none_assumed -Xcudafe --diag_suppress=dll_interface_conflict_dllexport_assumed -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm90 -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\include -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\tools\util\include "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include\torch\csrc\api\include" "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.44.35207\include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Auxiliary\VS\include" "-IC:\Program Files (x86)\Windows Kits\10\include\10.0.26100.0\ucrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\um" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\shared" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\winrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\cppwinrt" "-IC:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um" -c C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\smxx\get_mla_metadata.cu -o C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\smxx\get_mla_metadata.obj -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -include msvc_compat.h -O3 -std=c++17 -DNDEBUG -D_USE_MATH_DEFINES -Wno-deprecated-declarations -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v,--register-usage-level=10 -Xcompiler /Zc:__cplusplus -Xcompiler /permissive- -Xcompiler /Zc:__cplusplus -DFLASH_MLA_DISABLE_SM90 -gencode arch=compute_100a,code=sm_100a -gencode arch=compute_100a,code=compute_100a -gencode arch=compute_120,code=sm_120 -gencode arch=compute_120,code=compute_120 --threads 32 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=cuda
get_mla_metadata.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
get_mla_metadata.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
get_mla_metadata.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
get_mla_metadata.cu
ptxas info    : 191 bytes gmem
ptxas info    : Compiling entry function '_Z23get_mla_metadata_kernel25GetDecodingMetadataParams' for 'sm_120'
ptxas info    : Function properties for _Z23get_mla_metadata_kernel25GetDecodingMetadataParams
    24 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 40 registers, used 0 barriers, 24 bytes cumulative stack size
ptxas info    : Compile time = 0.000 ms
ptxas info    : 191 bytes gmem
ptxas info    : Compiling entry function '_Z23get_mla_metadata_kernel25GetDecodingMetadataParams' for 'sm_100a'
ptxas info    : Function properties for _Z23get_mla_metadata_kernel25GetDecodingMetadataParams
    24 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 40 registers, used 0 barriers, 24 bytes cumulative stack size
ptxas info    : Compile time = 0.000 ms
tmpxft_00002670_00000000-7_get_mla_metadata.compute_120.cudafe1.cpp
[3/7] C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin\nvcc --generate-dependencies-with-compile --dependency-output C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\smxx\mla_combine.obj.d -std=c++17 -Xcompiler /MD -Xcompiler /wd4819 -Xcompiler /wd4251 -Xcompiler /wd4244 -Xcompiler /wd4267 -Xcompiler /wd4275 -Xcompiler /wd4018 -Xcompiler /wd4190 -Xcompiler /wd4624 -Xcompiler /wd4067 -Xcompiler /wd4068 -Xcompiler /EHsc --use-local-env -Xcudafe --diag_suppress=base_class_has_different_dll_interface -Xcudafe --diag_suppress=field_without_dll_interface -Xcudafe --diag_suppress=dll_interface_conflict_none_assumed -Xcudafe --diag_suppress=dll_interface_conflict_dllexport_assumed -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm90 -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\include -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\tools\util\include "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include\torch\csrc\api\include" "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.44.35207\include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Auxiliary\VS\include" "-IC:\Program Files (x86)\Windows Kits\10\include\10.0.26100.0\ucrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\um" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\shared" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\winrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\cppwinrt" "-IC:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um" -c C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\smxx\mla_combine.cu -o C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\smxx\mla_combine.obj -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -include msvc_compat.h -O3 -std=c++17 -DNDEBUG -D_USE_MATH_DEFINES -Wno-deprecated-declarations -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v,--register-usage-level=10 -Xcompiler /Zc:__cplusplus -Xcompiler /permissive- -Xcompiler /Zc:__cplusplus -DFLASH_MLA_DISABLE_SM90 -gencode arch=compute_100a,code=sm_100a -gencode arch=compute_100a,code=compute_100a -gencode arch=compute_120,code=sm_120 -gencode arch=compute_120,code=compute_120 --threads 32 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=cuda
mla_combine.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
mla_combine.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
mla_combine.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
mla_combine.cu
ptxas info    : 152 bytes gmem
ptxas info    : Compiling entry function '_Z28flash_fwd_mla_combine_kernelIN7cutlass6half_tELi512ELi8ELi64ELi256EEv14DecodingParams' for 'sm_100a'
ptxas info    : Function properties for _Z28flash_fwd_mla_combine_kernelIN7cutlass6half_tELi512ELi8ELi64ELi256EEv14DecodingParams
    24 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, used 1 barriers, 24 bytes cumulative stack size
ptxas info    : Compile time = 0.000 ms
ptxas info    : Compiling entry function '_Z28flash_fwd_mla_combine_kernelIN7cutlass6half_tELi512ELi8ELi32ELi256EEv14DecodingParams' for 'sm_100a'
ptxas info    : Function properties for _Z28flash_fwd_mla_combine_kernelIN7cutlass6half_tELi512ELi8ELi32ELi256EEv14DecodingParams
    24 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, used 1 barriers, 24 bytes cumulative stack size
ptxas info    : Compile time = 0.000 ms
ptxas info    : Compiling entry function '_Z28flash_fwd_mla_combine_kernelIN7cutlass10bfloat16_tELi512ELi8ELi64ELi256EEv14DecodingParams' for 'sm_100a'
ptxas info    : Function properties for _Z28flash_fwd_mla_combine_kernelIN7cutlass10bfloat16_tELi512ELi8ELi64ELi256EEv14DecodingParams
    24 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, used 1 barriers, 24 bytes cumulative stack size
ptxas info    : Compile time = 0.000 ms
ptxas info    : Compiling entry function '_Z28flash_fwd_mla_combine_kernelIN7cutlass10bfloat16_tELi512ELi8ELi32ELi256EEv14DecodingParams' for 'sm_100a'
ptxas info    : Function properties for _Z28flash_fwd_mla_combine_kernelIN7cutlass10bfloat16_tELi512ELi8ELi32ELi256EEv14DecodingParams
    24 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, used 1 barriers, 24 bytes cumulative stack size
ptxas info    : Compile time = 0.000 ms
ptxas info    : 152 bytes gmem
ptxas info    : Compiling entry function '_Z28flash_fwd_mla_combine_kernelIN7cutlass6half_tELi512ELi8ELi64ELi256EEv14DecodingParams' for 'sm_120'
ptxas info    : Function properties for _Z28flash_fwd_mla_combine_kernelIN7cutlass6half_tELi512ELi8ELi64ELi256EEv14DecodingParams
    24 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 40 registers, used 1 barriers, 24 bytes cumulative stack size
ptxas info    : Compile time = 0.000 ms
ptxas info    : Compiling entry function '_Z28flash_fwd_mla_combine_kernelIN7cutlass6half_tELi512ELi8ELi32ELi256EEv14DecodingParams' for 'sm_120'
ptxas info    : Function properties for _Z28flash_fwd_mla_combine_kernelIN7cutlass6half_tELi512ELi8ELi32ELi256EEv14DecodingParams
    24 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 40 registers, used 1 barriers, 24 bytes cumulative stack size
ptxas info    : Compile time = 0.000 ms
ptxas info    : Compiling entry function '_Z28flash_fwd_mla_combine_kernelIN7cutlass10bfloat16_tELi512ELi8ELi64ELi256EEv14DecodingParams' for 'sm_120'
ptxas info    : Function properties for _Z28flash_fwd_mla_combine_kernelIN7cutlass10bfloat16_tELi512ELi8ELi64ELi256EEv14DecodingParams
    24 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 40 registers, used 1 barriers, 24 bytes cumulative stack size
ptxas info    : Compile time = 0.000 ms
ptxas info    : Compiling entry function '_Z28flash_fwd_mla_combine_kernelIN7cutlass10bfloat16_tELi512ELi8ELi32ELi256EEv14DecodingParams' for 'sm_120'
ptxas info    : Function properties for _Z28flash_fwd_mla_combine_kernelIN7cutlass10bfloat16_tELi512ELi8ELi32ELi256EEv14DecodingParams
    24 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 40 registers, used 1 barriers, 24 bytes cumulative stack size
ptxas info    : Compile time = 0.000 ms
tmpxft_00005374_00000000-7_mla_combine.compute_120.cudafe1.cpp
[4/7] cl /showIncludes /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm90 -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\include -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\tools\util\include "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include\torch\csrc\api\include" "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.44.35207\include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Auxiliary\VS\include" "-IC:\Program Files (x86)\Windows Kits\10\include\10.0.26100.0\ucrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\um" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\shared" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\winrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\cppwinrt" "-IC:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um" /MD /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /wd4624 /wd4067 /wd4068 /EHsc -c C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\pybind.cpp /FoC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\pybind.obj /O2 /std:c++17 /Zc:__cplusplus /EHsc /permissive- /DNOMINMAX /DWIN32_LEAN_AND_MEAN /D_HAS_EXCEPTIONS=1 /utf-8 /DNDEBUG /W0 /FImsvc_compat.h /DFLASH_MLA_DISABLE_SM90 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=cuda
cl : Command line warning D9025 : overriding '/W3' with '/W0'
[5/7] C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin\nvcc --generate-dependencies-with-compile --dependency-output C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\decode\sparse_fp8\splitkv_mla.obj.d -std=c++17 -Xcompiler /MD -Xcompiler /wd4819 -Xcompiler /wd4251 -Xcompiler /wd4244 -Xcompiler /wd4267 -Xcompiler /wd4275 -Xcompiler /wd4018 -Xcompiler /wd4190 -Xcompiler /wd4624 -Xcompiler /wd4067 -Xcompiler /wd4068 -Xcompiler /EHsc --use-local-env -Xcudafe --diag_suppress=base_class_has_different_dll_interface -Xcudafe --diag_suppress=field_without_dll_interface -Xcudafe --diag_suppress=dll_interface_conflict_none_assumed -Xcudafe --diag_suppress=dll_interface_conflict_dllexport_assumed -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm90 -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\include -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\tools\util\include "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include\torch\csrc\api\include" "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.44.35207\include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Auxiliary\VS\include" "-IC:\Program Files (x86)\Windows Kits\10\include\10.0.26100.0\ucrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\um" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\shared" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\winrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\cppwinrt" "-IC:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um" -c C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\decode\sparse_fp8\splitkv_mla.cu -o C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\decode\sparse_fp8\splitkv_mla.obj -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -include msvc_compat.h -O3 -std=c++17 -DNDEBUG -D_USE_MATH_DEFINES -Wno-deprecated-declarations -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v,--register-usage-level=10 -Xcompiler /Zc:__cplusplus -Xcompiler /permissive- -Xcompiler /Zc:__cplusplus -DFLASH_MLA_DISABLE_SM90 -gencode arch=compute_100a,code=sm_100a -gencode arch=compute_100a,code=compute_100a -gencode arch=compute_120,code=sm_120 -gencode arch=compute_120,code=compute_120 --threads 32 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=cuda
FAILED: [code=4294967295] C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/build/temp.win-amd64-cpython-312/Release/csrc/sm100/decode/sparse_fp8/splitkv_mla.obj 
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin\nvcc --generate-dependencies-with-compile --dependency-output C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\decode\sparse_fp8\splitkv_mla.obj.d -std=c++17 -Xcompiler /MD -Xcompiler /wd4819 -Xcompiler /wd4251 -Xcompiler /wd4244 -Xcompiler /wd4267 -Xcompiler /wd4275 -Xcompiler /wd4018 -Xcompiler /wd4190 -Xcompiler /wd4624 -Xcompiler /wd4067 -Xcompiler /wd4068 -Xcompiler /EHsc --use-local-env -Xcudafe --diag_suppress=base_class_has_different_dll_interface -Xcudafe --diag_suppress=field_without_dll_interface -Xcudafe --diag_suppress=dll_interface_conflict_none_assumed -Xcudafe --diag_suppress=dll_interface_conflict_dllexport_assumed -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm90 -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\include -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\tools\util\include "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include\torch\csrc\api\include" "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.44.35207\include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Auxiliary\VS\include" "-IC:\Program Files (x86)\Windows Kits\10\include\10.0.26100.0\ucrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\um" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\shared" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\winrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\cppwinrt" "-IC:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um" -c C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\decode\sparse_fp8\splitkv_mla.cu -o C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\decode\sparse_fp8\splitkv_mla.obj -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -include msvc_compat.h -O3 -std=c++17 -DNDEBUG -D_USE_MATH_DEFINES -Wno-deprecated-declarations -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v,--register-usage-level=10 -Xcompiler /Zc:__cplusplus -Xcompiler /permissive- -Xcompiler /Zc:__cplusplus -DFLASH_MLA_DISABLE_SM90 -gencode arch=compute_100a,code=sm_100a -gencode arch=compute_100a,code=compute_100a -gencode arch=compute_120,code=sm_120 -gencode arch=compute_120,code=compute_120 --threads 32 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=cuda
splitkv_mla.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
splitkv_mla.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
splitkv_mla.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
splitkv_mla.cu
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 3590; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 3594; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 3594; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4019; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4019; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4219; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4219; error   : Instruction 'tcgen05.st' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4228; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4228; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4428; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4428; error   : Instruction 'tcgen05.st' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4437; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4437; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4637; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4637; error   : Instruction 'tcgen05.st' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4646; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4646; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4846; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4846; error   : Instruction 'tcgen05.st' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4964; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4972; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 4972; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 5125; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 5125; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 5278; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 5278; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 5431; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 5431; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 5964; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 5964; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6105; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6105; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6246; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6246; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6387; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6387; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6528; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6528; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6669; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6669; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6810; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6810; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6951; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 6951; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8591; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8621; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8707; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8707; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8707; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8716; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8716; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8716; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8724; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8724; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8724; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8732; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8732; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8732; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8740; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8740; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8740; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8748; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8748; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8748; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8756; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8756; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8756; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8764; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8764; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8764; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8772; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8772; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8772; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8780; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8780; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8780; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8788; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8788; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8788; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8796; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8796; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8796; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8804; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8804; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8804; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8812; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8812; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8812; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8820; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8820; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8820; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8828; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8828; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8828; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8836; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8836; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8836; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8844; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8844; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8844; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8852; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8852; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8852; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8860; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8860; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8860; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8868; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8868; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8868; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8876; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8876; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8876; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8884; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8884; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8884; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8892; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8892; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8892; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8900; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8900; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8900; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8908; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8908; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8908; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8916; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8916; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8916; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8924; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8924; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8924; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8932; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8932; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8932; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8940; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8940; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8940; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8948; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8948; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8948; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8956; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8956; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8956; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8964; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8964; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8964; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8972; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8972; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8972; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8980; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8980; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8980; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8988; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8988; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8988; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8994; error   : Instruction 'tcgen05.commit' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 8994; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9008; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9033; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9033; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9033; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9042; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9042; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9042; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9050; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9050; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9050; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9058; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9058; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9058; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9066; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9066; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9066; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9074; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9074; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9074; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9082; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9082; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9082; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9090; error   : Instruction 'tcgen05.mma.ws' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9090; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9090; error   : Feature '.kind::f16' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9096; error   : Instruction 'tcgen05.commit' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_00003a14_00000000-7_splitkv_mla.compute_120.ptx, line 9096; error   : Feature '.cta_group::1' not supported on .target 'sm_120'
ptxas fatal   : Ptx assembly aborted due to errors
ptxas info    : 11 bytes gmem
ptxas info    : Compiling entry function '_ZN5sm10039flash_fwd_splitkv_mla_fp8_sparse_kernelINS_9TmaParamsIN4cute5tupleIJiiiiEEENS2_9TiledCopyINS2_9Copy_AtomIJNS2_11Copy_TraitsINS2_13SM90_TMA_LOADEJNS2_1CILi65536EEENS2_12AuxTmaParamsINS3_IJNS2_11ScaledBasisINS9_ILi1EEELi1EEENSC_ISD_Li0EEENSC_ISD_Li2EEENSC_ISD_Li3EEEEEERKNS2_6LayoutINS3_IJNS9_ILi64EEESK_SD_SD_EEESI_EERKNS2_7SwizzleILi3ELi4ELi3EEEEEEEEN7cutlass10bfloat16_tEEEENSJ_INS3_IJSD_NS3_IJNS3_IJNS3_IJSK_SK_EEENS9_ILi9EEEEEEEEEEEENS3_IJNS9_ILi0EEENS3_IJNS3_IJNS3_IJSK_SD_EEENS9_ILi4096EEEEEEEEEEEEEENS3_IJSK_NS9_ILi576EEEEEEEES4_NS5_INS6_IJNS7_INS2_14SM90_TMA_STOREEJNS9_ILi8192EEENSB_ISI_RKNSJ_INS3_IJNS9_ILi8EEESK_SD_SD_EEESI_EERKNSP_ILi0ELi4ELi3EEEEEEEESW_EEENSJ_INS3_IJSD_NS3_IJNS3_IJNS3_IJS1F_SK_EEESK_EEEEEEEEENS3_IJS13_NS3_IJNS3_IJS14_NS9_ILi512EEEEEEEEEEEEEENS3_IJSK_S1U_EEEEEEEEEv14DecodingParamsT_' for 'sm_100a'
ptxas info    : Function properties for _ZN5sm10039flash_fwd_splitkv_mla_fp8_sparse_kernelINS_9TmaParamsIN4cute5tupleIJiiiiEEENS2_9TiledCopyINS2_9Copy_AtomIJNS2_11Copy_TraitsINS2_13SM90_TMA_LOADEJNS2_1CILi65536EEENS2_12AuxTmaParamsINS3_IJNS2_11ScaledBasisINS9_ILi1EEELi1EEENSC_ISD_Li0EEENSC_ISD_Li2EEENSC_ISD_Li3EEEEEERKNS2_6LayoutINS3_IJNS9_ILi64EEESK_SD_SD_EEESI_EERKNS2_7SwizzleILi3ELi4ELi3EEEEEEEEN7cutlass10bfloat16_tEEEENSJ_INS3_IJSD_NS3_IJNS3_IJNS3_IJSK_SK_EEENS9_ILi9EEEEEEEEEEEENS3_IJNS9_ILi0EEENS3_IJNS3_IJNS3_IJSK_SD_EEENS9_ILi4096EEEEEEEEEEEEEENS3_IJSK_NS9_ILi576EEEEEEEES4_NS5_INS6_IJNS7_INS2_14SM90_TMA_STOREEJNS9_ILi8192EEENSB_ISI_RKNSJ_INS3_IJNS9_ILi8EEESK_SD_SD_EEESI_EERKNSP_ILi0ELi4ELi3EEEEEEEESW_EEENSJ_INS3_IJSD_NS3_IJNS3_IJNS3_IJS1F_SK_EEESK_EEEEEEEEENS3_IJS13_NS3_IJNS3_IJS14_NS9_ILi512EEEEEEEEEEEEEENS3_IJSK_S1U_EEEEEEEEEv14DecodingParamsT_
    88 bytes stack frame, 88 bytes spill stores, 180 bytes spill loads
ptxas info    : Used 168 registers, used 10 barriers, 88 bytes cumulative stack size
ptxas info    : Compile time = 0.000 ms
[6/7] C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin\nvcc --generate-dependencies-with-compile --dependency-output C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\sparse\fwd.obj.d -std=c++17 -Xcompiler /MD -Xcompiler /wd4819 -Xcompiler /wd4251 -Xcompiler /wd4244 -Xcompiler /wd4267 -Xcompiler /wd4275 -Xcompiler /wd4018 -Xcompiler /wd4190 -Xcompiler /wd4624 -Xcompiler /wd4067 -Xcompiler /wd4068 -Xcompiler /EHsc --use-local-env -Xcudafe --diag_suppress=base_class_has_different_dll_interface -Xcudafe --diag_suppress=field_without_dll_interface -Xcudafe --diag_suppress=dll_interface_conflict_none_assumed -Xcudafe --diag_suppress=dll_interface_conflict_dllexport_assumed -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm90 -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\include -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\tools\util\include "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include\torch\csrc\api\include" "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.44.35207\include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Auxiliary\VS\include" "-IC:\Program Files (x86)\Windows Kits\10\include\10.0.26100.0\ucrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\um" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\shared" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\winrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\cppwinrt" "-IC:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um" -c C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\sparse\fwd.cu -o C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\sparse\fwd.obj -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -include msvc_compat.h -O3 -std=c++17 -DNDEBUG -D_USE_MATH_DEFINES -Wno-deprecated-declarations -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v,--register-usage-level=10 -Xcompiler /Zc:__cplusplus -Xcompiler /permissive- -Xcompiler /Zc:__cplusplus -DFLASH_MLA_DISABLE_SM90 -gencode arch=compute_100a,code=sm_100a -gencode arch=compute_100a,code=compute_100a -gencode arch=compute_120,code=sm_120 -gencode arch=compute_120,code=compute_120 --threads 32 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=cuda
FAILED: [code=4294967295] C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/build/temp.win-amd64-cpython-312/Release/csrc/sm100/prefill/sparse/fwd.obj 
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin\nvcc --generate-dependencies-with-compile --dependency-output C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\sparse\fwd.obj.d -std=c++17 -Xcompiler /MD -Xcompiler /wd4819 -Xcompiler /wd4251 -Xcompiler /wd4244 -Xcompiler /wd4267 -Xcompiler /wd4275 -Xcompiler /wd4018 -Xcompiler /wd4190 -Xcompiler /wd4624 -Xcompiler /wd4067 -Xcompiler /wd4068 -Xcompiler /EHsc --use-local-env -Xcudafe --diag_suppress=base_class_has_different_dll_interface -Xcudafe --diag_suppress=field_without_dll_interface -Xcudafe --diag_suppress=dll_interface_conflict_none_assumed -Xcudafe --diag_suppress=dll_interface_conflict_dllexport_assumed -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm90 -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\include -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\tools\util\include "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include\torch\csrc\api\include" "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.44.35207\include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Auxiliary\VS\include" "-IC:\Program Files (x86)\Windows Kits\10\include\10.0.26100.0\ucrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\um" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\shared" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\winrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\cppwinrt" "-IC:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um" -c C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\sparse\fwd.cu -o C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\sparse\fwd.obj -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -include msvc_compat.h -O3 -std=c++17 -DNDEBUG -D_USE_MATH_DEFINES -Wno-deprecated-declarations -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v,--register-usage-level=10 -Xcompiler /Zc:__cplusplus -Xcompiler /permissive- -Xcompiler /Zc:__cplusplus -DFLASH_MLA_DISABLE_SM90 -gencode arch=compute_100a,code=sm_100a -gencode arch=compute_100a,code=compute_100a -gencode arch=compute_120,code=sm_120 -gencode arch=compute_120,code=compute_120 --threads 32 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=cuda
fwd.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
fwd.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
fwd.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
fwd.cu
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 596; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 600; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 600; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 672; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1403; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1407; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1407; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1511; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1511; error   : Instruction 'tcgen05.st' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1520; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1520; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1624; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1624; error   : Instruction 'tcgen05.st' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1633; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1633; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1737; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1737; error   : Instruction 'tcgen05.st' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1746; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1746; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1850; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1850; error   : Instruction 'tcgen05.st' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1859; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1859; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1963; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1963; error   : Instruction 'tcgen05.st' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1972; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 1972; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2076; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2076; error   : Instruction 'tcgen05.st' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2085; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2085; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2189; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2189; error   : Instruction 'tcgen05.st' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2198; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2198; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2302; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2302; error   : Instruction 'tcgen05.st' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2310; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2385; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2461; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2461; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2860; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 2860; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 3288; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 3288; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 3716; error   : Feature '.32x32b' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 3716; error   : Instruction 'tcgen05.ld' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4283; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4288; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4293; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4298; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4302; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4306; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4310; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4314; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4318; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4322; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4326; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4330; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4334; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4338; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4342; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4346; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4376; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4381; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4386; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4391; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4396; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4400; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4404; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4408; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4412; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4416; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4420; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4424; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4428; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4432; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4436; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4440; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4444; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4448; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4452; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4456; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4586; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4590; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4594; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4598; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4606; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4610; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4614; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4618; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4625; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4629; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4633; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4637; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4645; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4649; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4653; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4657; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4690; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4694; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4698; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4702; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4710; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4714; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4718; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4722; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4730; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4734; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4738; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4742; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4750; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4754; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4758; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4762; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 4812; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 5500; error   : Instruction 'tcgen05.commit' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 5500; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 5561; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 5840; error   : Instruction 'tcgen05.commit' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 5840; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 5862; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 6208; error   : Instruction 'tcgen05.commit' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 6208; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 6252; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 6395; error   : Instruction 'tcgen05.commit' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 6395; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 6415; error   : Instruction 'tcgen05.fence' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 6556; error   : Instruction 'tcgen05.commit' not supported on .target 'sm_120'
ptxas C:/Users/SHASHA~1/AppData/Local/Temp/tmpxft_000069a4_00000000-7_fwd.compute_120.ptx, line 6556; error   : Feature '.cta_group::2' not supported on .target 'sm_120'
ptxas fatal   : Ptx assembly aborted due to errors
ptxas info    : 11 bytes gmem
ptxas info    : Compiling entry function '_ZN5sm10022sparse_attn_fwd_kernelINS_9TmaParamsIN4cute5tupleIJiiiEEENS2_9TiledCopyINS2_9Copy_AtomIJNS2_11Copy_TraitsINS2_26SM100_TMA_2SM_LOAD_NOSPLITEJNS2_1CILi65536EEENS2_12AuxTmaParamsINS3_IJNS2_11ScaledBasisINS9_ILi1EEELi1EEENSC_ISD_Li0EEENSC_ISD_Li2EEEEEERKNS2_6LayoutINS3_IJNS9_ILi64EEESJ_SD_EEESH_EERKNS2_7SwizzleILi3ELi4ELi3EEEEEEEEN7cutlass10bfloat16_tEEEENSI_INS3_IJSD_NS3_IJNS3_IJNS3_IJSJ_SJ_EEENS9_ILi9EEEEEEEEEEEENS3_IJNS9_ILi0EEENS3_IJNS3_IJNS3_IJSJ_SD_EEENS9_ILi4096EEEEEEEEEEEEEENS3_IJSJ_NS9_ILi576EEEEEEEES4_NS5_INS6_IJNS7_INS2_14SM90_TMA_STOREEJSA_SS_EEESV_EEENSI_INS3_IJSD_NS3_IJNS3_IJSX_SD_EEEEEEEEENS3_IJS12_NS3_IJNS3_IJS13_S12_EEEEEEEEEEESX_EEEEEEv19SparsePrefillParamsT_' for 'sm_100a'
ptxas info    : Function properties for _ZN5sm10022sparse_attn_fwd_kernelINS_9TmaParamsIN4cute5tupleIJiiiEEENS2_9TiledCopyINS2_9Copy_AtomIJNS2_11Copy_TraitsINS2_26SM100_TMA_2SM_LOAD_NOSPLITEJNS2_1CILi65536EEENS2_12AuxTmaParamsINS3_IJNS2_11ScaledBasisINS9_ILi1EEELi1EEENSC_ISD_Li0EEENSC_ISD_Li2EEEEEERKNS2_6LayoutINS3_IJNS9_ILi64EEESJ_SD_EEESH_EERKNS2_7SwizzleILi3ELi4ELi3EEEEEEEEN7cutlass10bfloat16_tEEEENSI_INS3_IJSD_NS3_IJNS3_IJNS3_IJSJ_SJ_EEENS9_ILi9EEEEEEEEEEEENS3_IJNS9_ILi0EEENS3_IJNS3_IJNS3_IJSJ_SD_EEENS9_ILi4096EEEEEEEEEEEEEENS3_IJSJ_NS9_ILi576EEEEEEEES4_NS5_INS6_IJNS7_INS2_14SM90_TMA_STOREEJSA_SS_EEESV_EEENSI_INS3_IJSD_NS3_IJNS3_IJSX_SD_EEEEEEEEENS3_IJS12_NS3_IJNS3_IJS13_S12_EEEEEEEEEEESX_EEEEEEv19SparsePrefillParamsT_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 128 registers, used 9 barriers
ptxas info    : Compile time = 0.000 ms
[7/7] C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin\nvcc --generate-dependencies-with-compile --dependency-output C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.obj.d -std=c++17 -Xcompiler /MD -Xcompiler /wd4819 -Xcompiler /wd4251 -Xcompiler /wd4244 -Xcompiler /wd4267 -Xcompiler /wd4275 -Xcompiler /wd4018 -Xcompiler /wd4190 -Xcompiler /wd4624 -Xcompiler /wd4067 -Xcompiler /wd4068 -Xcompiler /EHsc --use-local-env -Xcudafe --diag_suppress=base_class_has_different_dll_interface -Xcudafe --diag_suppress=field_without_dll_interface -Xcudafe --diag_suppress=dll_interface_conflict_none_assumed -Xcudafe --diag_suppress=dll_interface_conflict_dllexport_assumed -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm90 -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\include -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\tools\util\include "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include\torch\csrc\api\include" "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.44.35207\include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Auxiliary\VS\include" "-IC:\Program Files (x86)\Windows Kits\10\include\10.0.26100.0\ucrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\um" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\shared" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\winrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\cppwinrt" "-IC:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um" -c C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu -o C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.obj -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -include msvc_compat.h -O3 -std=c++17 -DNDEBUG -D_USE_MATH_DEFINES -Wno-deprecated-declarations -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v,--register-usage-level=10 -Xcompiler /Zc:__cplusplus -Xcompiler /permissive- -Xcompiler /Zc:__cplusplus -DFLASH_MLA_DISABLE_SM90 -gencode arch=compute_100a,code=sm_100a -gencode arch=compute_100a,code=compute_100a -gencode arch=compute_120,code=sm_120 -gencode arch=compute_120,code=compute_120 --threads 32 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=cuda
FAILED: [code=4294967295] C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/build/temp.win-amd64-cpython-312/Release/csrc/sm100/prefill/dense/fmha_cutlass_fwd_sm100.obj 
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin\nvcc --generate-dependencies-with-compile --dependency-output C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.obj.d -std=c++17 -Xcompiler /MD -Xcompiler /wd4819 -Xcompiler /wd4251 -Xcompiler /wd4244 -Xcompiler /wd4267 -Xcompiler /wd4275 -Xcompiler /wd4018 -Xcompiler /wd4190 -Xcompiler /wd4624 -Xcompiler /wd4067 -Xcompiler /wd4068 -Xcompiler /EHsc --use-local-env -Xcudafe --diag_suppress=base_class_has_different_dll_interface -Xcudafe --diag_suppress=field_without_dll_interface -Xcudafe --diag_suppress=dll_interface_conflict_none_assumed -Xcudafe --diag_suppress=dll_interface_conflict_dllexport_assumed -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm90 -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\include -IC:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\cutlass\tools\util\include "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\include\torch\csrc\api\include" "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\include" "-IC:\Users\Shashank Murthy\.conda\envs\150BLLM\Include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.44.35207\include" "-IC:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Auxiliary\VS\include" "-IC:\Program Files (x86)\Windows Kits\10\include\10.0.26100.0\ucrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\um" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\shared" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\winrt" "-IC:\Program Files (x86)\Windows Kits\10\\include\10.0.26100.0\\cppwinrt" "-IC:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um" -c C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu -o C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\build\temp.win-amd64-cpython-312\Release\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.obj -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -include msvc_compat.h -O3 -std=c++17 -DNDEBUG -D_USE_MATH_DEFINES -Wno-deprecated-declarations -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v,--register-usage-level=10 -Xcompiler /Zc:__cplusplus -Xcompiler /permissive- -Xcompiler /Zc:__cplusplus -DFLASH_MLA_DISABLE_SM90 -gencode arch=compute_100a,code=sm_100a -gencode arch=compute_100a,code=compute_100a -gencode arch=compute_120,code=sm_120 -gencode arch=compute_120,code=compute_120 --threads 32 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=cuda
fmha_cutlass_fwd_sm100.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
fmha_cutlass_fwd_sm100.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
fmha_cutlass_fwd_sm100.cu
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_OPERATORS__' with '/U__CUDA_NO_HALF_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF_CONVERSIONS__' with '/U__CUDA_NO_HALF_CONVERSIONS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_HALF2_OPERATORS__' with '/U__CUDA_NO_HALF2_OPERATORS__'
cl : Command line warning D9025 : overriding '/D__CUDA_NO_BFLOAT16_CONVERSIONS__' with '/U__CUDA_NO_BFLOAT16_CONVERSIONS__'
fmha_cutlass_fwd_sm100.cu
C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(181): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(263): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(309): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/pipeline/sm90_pipeline.hpp(333): warning #177-D: variable "thread_idx" was declared but never referenced
      int thread_idx = threadIdx.x;
          ^
          detected during:
            instantiation of "cutlass::PipelineTmaAsync<Stages_>::PipelineTmaAsync(cutlass::PipelineTmaAsync<Stages_>::SharedStorage &, cutlass::PipelineTmaAsync<Stages_>::Params, ClusterShape, InitBarriers, InitMasks) [with Stages_=2, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, InitBarriers=cute::false_type, InitMasks=cute::false_type]" at line 563 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/pipeline/sm100_pipeline.hpp
            instantiation of "cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::PipelineTmaUmmaAsync(cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::SharedStorage &, cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::Params, ClusterShape, InitBarriers, InitMasks) [with Stages_=2, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, AtomThrShape_MNK_=cute::tuple<cute::_1, cute::_1, cute::_1>, InitBarriers=cute::true_type, InitMasks=cute::false_type]" at line 313 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/pipeline/sm100_pipeline.hpp(538): warning #177-D: variable "cluster_layout" was declared but never referenced
        auto cluster_layout = make_layout(cluster_shape);
             ^
          detected during:
            instantiation of "void cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::init_masks(ClusterShape, dim3) [with Stages_=2, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, AtomThrShape_MNK_=cute::tuple<cute::_1, cute::_1, cute::_1>]" at line 420 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective\../common/pipeline_mla.hpp(114): warning #177-D: variable "cluster_layout" was declared but never referenced
        auto cluster_layout = make_layout(cluster_shape);
             ^
          detected during:
            instantiation of "void cutlass::PipelineTmaAsyncMla<Stages_, ClusterShape, AtomThrShape_MNK_>::init_masks(ClusterShape, dim3) [with Stages_=2, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, AtomThrShape_MNK_=cute::tuple<cute::_1, cute::_1, cute::_1>]" at line 421 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp(522): error: static assertion failed with "The memory pointed to by AtomTVLayout does not exist in the DataLayout."
    static_assert(decltype(coalesce(composition(data_layout, layout<1>(layout_tv_data))) == coalesce(layout<1>(atom_tv_layout)))::value,"The memory pointed to by AtomTVLayout does not exist in the DataLayout.");
    ^
          detected during:
            instantiation of "auto cute::make_cotiled_copy(const cute::Copy_Atom<Args...> &, const AtomTVLayout &, const DataLayout &) [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x, float>, AtomTVLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::C<32>, cute::C<32>>>, cute::tuple<cute::tuple<cute::_0, cute::C<2097152>>, cute::tuple<cute::_1, cute::C<65536>>>>, DataLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<64>>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>>, cute::_1>, cute::C<0>, cute::C<0>>>]" at line 272 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const cute::Copy_Atom<CopyOp, CopyT> &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x, CopyT=float, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<64>>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>>, cute::_1>, cute::C<0>, cute::C<0>>>]" at line 282 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const CopyOp &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<64>>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>>, cute::_1>, cute::C<0>, cute::C<0>>>]" at line 567 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1213): error: static assertion failed with "Non-injective Layout detected in complement."
      static_assert(! is_constant<0, decltype(new_shape)>::value, "Non-injective Layout detected in complement.");
      ^
          detected during:
            instantiation of "auto cute::detail::complement(const Shape &, const Stride &, const CoTarget &) [with Shape=cute::tuple<cute::C<128>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_16, cute::_4, cute::_64>]" at line 1237
            instantiation of "auto cute::complement(const cute::Layout<Shape, Stride> &, const CoTarget &) [with Shape=cute::tuple<cute::C<128>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_16, cute::_4, cute::_64>]" at line 1578
            instantiation of "auto cute::logical_divide(const cute::Layout<LShape, LStride> &, const cute::Layout<TShape, TStride> &) [with LShape=cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<64>>, LStride=cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>>, cute::_1>, TShape=cute::tuple<cute::C<128>, cute::C<32>>, TStride=cute::tuple<cute::_16, cute::_1>]" at line 1589
            instantiation of function "lambda [](const auto &, const auto &)->auto [with <auto-1>=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<64>>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>>, cute::_1>>, <auto-2>=cute::Layout<cute::tuple<cute::C<128>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>]" at line 743
            instantiation of "auto cute::detail::transform_layout(const Tuple0 &, const Tuple1 &, F &&, cute::seq<I...>, cute::seq<I0...>, cute::seq<I1...>) [with Tuple0=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<64>>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>>, cute::_1>, cute::C<0>, cute::C<0>>>, Tuple1=cute::tuple<cute::Layout<cute::tuple<cute::C<128>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>, cute::Layout<cute::_1, cute::C<0>>>, F=lambda [](const auto &, const auto &)->auto &, I=<0, 1, 2>, I0=<>, I1=<>]" at line 764
            [ 8 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, <auto-2>=cute::integral_constant<int, 1>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, X=cute::integral_constant<int, 1>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0, 1>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_16, cute::_4, cute::_64>, LStride=cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 20 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, <auto-2>=cute::integral_constant<int, 1>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, X=cute::integral_constant<int, 1>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0, 1>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_16, cute::_4, cute::_64>, LStride=cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 20 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1213): error: static assertion failed with "Non-injective Layout detected in complement."
      static_assert(! is_constant<0, decltype(new_shape)>::value, "Non-injective Layout detected in complement.");
      ^
          detected during:
            instantiation of "auto cute::detail::complement(const Shape &, const Stride &, const CoTarget &) [with Shape=cute::tuple<cute::C<128>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::C<64>, cute::C<64>>]" at line 1237
            instantiation of "auto cute::complement(const cute::Layout<Shape, Stride> &, const CoTarget &) [with Shape=cute::tuple<cute::C<128>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::C<64>, cute::C<64>>]" at line 1578
            instantiation of "auto cute::logical_divide(const cute::Layout<LShape, LStride> &, const cute::Layout<TShape, TStride> &) [with LShape=cute::tuple<cute::C<64>, cute::C<64>>, LStride=cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, TShape=cute::tuple<cute::C<128>, cute::C<32>>, TStride=cute::tuple<cute::_16, cute::_1>]" at line 1589
            instantiation of function "lambda [](const auto &, const auto &)->auto [with <auto-1>=cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>, <auto-2>=cute::Layout<cute::tuple<cute::C<128>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>]" at line 743
            instantiation of "auto cute::detail::transform_layout(const Tuple0 &, const Tuple1 &, F &&, cute::seq<I...>, cute::seq<I0...>, cute::seq<I1...>) [with Tuple0=cute::Layout<cute::tuple<cute::tuple<cute::C<64>, cute::C<64>>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::C<0>, cute::C<0>>>, Tuple1=cute::tuple<cute::Layout<cute::tuple<cute::C<128>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>, cute::Layout<cute::_1, cute::C<0>>>, F=lambda [](const auto &, const auto &)->auto &, I=<0, 1, 2>, I0=<>, I1=<>]" at line 764
            [ 8 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::C<64>, cute::C<64>>, LStride=cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 20 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::C<64>, cute::C<64>>, LStride=cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 20 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp(522): error: static assertion failed with "The memory pointed to by AtomTVLayout does not exist in the DataLayout."
    static_assert(decltype(coalesce(composition(data_layout, layout<1>(layout_tv_data))) == coalesce(layout<1>(atom_tv_layout)))::value,"The memory pointed to by AtomTVLayout does not exist in the DataLayout.");
    ^
          detected during:
            instantiation of "auto cute::make_cotiled_copy(const cute::Copy_Atom<Args...> &, const AtomTVLayout &, const DataLayout &) [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x, float>, AtomTVLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::_2, cute::C<32>>>, cute::tuple<cute::tuple<cute::_0, cute::C<2097152>>, cute::tuple<cute::_1, cute::C<65536>>>>, DataLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 272 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const cute::Copy_Atom<CopyOp, CopyT> &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x, CopyT=float, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 282 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const CopyOp &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 573 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1213): error: static assertion failed with "Non-injective Layout detected in complement."
      static_assert(! is_constant<0, decltype(new_shape)>::value, "Non-injective Layout detected in complement.");
      ^
          detected during:
            instantiation of "auto cute::detail::complement(const Shape &, const Stride &, const CoTarget &) [with Shape=cute::tuple<cute::C<8>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_16, cute::_4, cute::C<2>>]" at line 1237
            instantiation of "auto cute::complement(const cute::Layout<Shape, Stride> &, const CoTarget &) [with Shape=cute::tuple<cute::C<8>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_16, cute::_4, cute::C<2>>]" at line 1578
            instantiation of "auto cute::logical_divide(const cute::Layout<LShape, LStride> &, const cute::Layout<TShape, TStride> &) [with LShape=cute::tuple<cute::_16, cute::_4, cute::C<2>>, LStride=cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, TShape=cute::tuple<cute::C<8>, cute::C<32>>, TStride=cute::tuple<cute::_16, cute::_1>]" at line 1589
            instantiation of function "lambda [](const auto &, const auto &)->auto [with <auto-1>=cute::Layout<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>>, <auto-2>=cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>]" at line 743
            instantiation of "auto cute::detail::transform_layout(const Tuple0 &, const Tuple1 &, F &&, cute::seq<I...>, cute::seq<I0...>, cute::seq<I1...>) [with Tuple0=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>, Tuple1=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>>, F=lambda [](const auto &, const auto &)->auto &, I=<0, 1>, I0=<>, I1=<>]" at line 764
            [ 8 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, <auto-2>=cute::integral_constant<int, 1>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, X=cute::integral_constant<int, 1>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0, 1>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_16, cute::_4, cute::C<2>>, LStride=cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 16 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, <auto-2>=cute::integral_constant<int, 1>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, X=cute::integral_constant<int, 1>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0, 1>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_16, cute::_4, cute::C<2>>, LStride=cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 16 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1213): error: static assertion failed with "Non-injective Layout detected in complement."
      static_assert(! is_constant<0, decltype(new_shape)>::value, "Non-injective Layout detected in complement.");
      ^
          detected during:
            instantiation of "auto cute::detail::complement(const Shape &, const Stride &, const CoTarget &) [with Shape=cute::tuple<cute::C<8>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_64, cute::_2>]" at line 1237
            instantiation of "auto cute::complement(const cute::Layout<Shape, Stride> &, const CoTarget &) [with Shape=cute::tuple<cute::C<8>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_64, cute::_2>]" at line 1578
            instantiation of "auto cute::logical_divide(const cute::Layout<LShape, LStride> &, const cute::Layout<TShape, TStride> &) [with LShape=cute::tuple<cute::_64, cute::_2>, LStride=cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, TShape=cute::tuple<cute::C<8>, cute::C<32>>, TStride=cute::tuple<cute::_16, cute::_1>]" at line 1589
            instantiation of function "lambda [](const auto &, const auto &)->auto [with <auto-1>=cute::Layout<cute::tuple<cute::_64, cute::_2>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>, <auto-2>=cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>]" at line 743
            instantiation of "auto cute::detail::transform_layout(const Tuple0 &, const Tuple1 &, F &&, cute::seq<I...>, cute::seq<I0...>, cute::seq<I1...>) [with Tuple0=cute::Layout<cute::tuple<cute::tuple<cute::_64, cute::_2>, cute::_2>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<2>, 1>>>, Tuple1=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>>, F=lambda [](const auto &, const auto &)->auto &, I=<0, 1>, I0=<>, I1=<>]" at line 764
            [ 8 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_64, cute::_2>, LStride=cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 16 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_64, cute::_2>, LStride=cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 16 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp(522): error: static assertion failed with "The memory pointed to by AtomTVLayout does not exist in the DataLayout."
    static_assert(decltype(coalesce(composition(data_layout, layout<1>(layout_tv_data))) == coalesce(layout<1>(atom_tv_layout)))::value,"The memory pointed to by AtomTVLayout does not exist in the DataLayout.");
    ^
          detected during:
            instantiation of "auto cute::make_cotiled_copy(const cute::Copy_Atom<Args...> &, const AtomTVLayout &, const DataLayout &) [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x, float>, AtomTVLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::C<32>, cute::C<32>>>, cute::tuple<cute::tuple<cute::_0, cute::C<2097152>>, cute::tuple<cute::_1, cute::C<65536>>>>, DataLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::C<32>>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 272 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const cute::Copy_Atom<CopyOp, CopyT> &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x, CopyT=float, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::C<32>>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 282 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const CopyOp &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::C<32>>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 579 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(370): error: static assertion failed with "Dynamic owning tensors not supported"
        static_assert((is_static<Arg0>::value && ... && is_static<Args>::value),
        ^
          detected during:
            instantiation of "auto cute::MakeTensor<T>::operator()(const Arg0 &, const Args &...) const [with T=float, Arg0=cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, Args=<>]" at line 401
            instantiation of "auto cute::make_tensor<T,Args...>(const Args &...) [with T=float, Args=<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>>]" at line 590 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(370): error: static assertion failed with "Dynamic owning tensors not supported"
        static_assert((is_static<Arg0>::value && ... && is_static<Args>::value),
        ^
          detected during:
            instantiation of "auto cute::MakeTensor<T>::operator()(const Arg0 &, const Args &...) const [with T=float, Arg0=cute::tuple<cute::tuple<cute::_2, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, Args=<>]" at line 401
            instantiation of "auto cute::make_tensor<T,Args...>(const Args &...) [with T=float, Args=<cute::tuple<cute::tuple<cute::_2, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>>]" at line 620 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(370): error: static assertion failed with "Dynamic owning tensors not supported"
        static_assert((is_static<Arg0>::value && ... && is_static<Args>::value),
        ^
          detected during:
            instantiation of "auto cute::MakeTensor<T>::operator()(const Arg0 &, const Args &...) const [with T=uint32_t, Arg0=cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, Args=<>]" at line 401
            instantiation of "auto cute::make_tensor<T,Args...>(const Args &...) [with T=uint32_t, Args=<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>>]" at line 636 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(684): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(357): error: static assertion failed with "Expected src to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(src)) == coalesce(upcast<sizeof_bits<SrcType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected src to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::LOAD::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x, TS=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::C<32>, cute::C<16>>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>, TD=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::C<32>, cute::C<16>>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::C<32>, cute::C<16>>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x, float>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::C<32>, cute::C<16>>, cute::_2>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::tuple<cute::C<4194304>, cute::C<1>>, cute::C<32>>, cute::C<0>, cute::C<0>>>, DstEngine=cute::ArrayEngine<float, 0ULL>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::C<32>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::_4, cute::tuple<cute::_128, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<128>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>, cute::Layout<cute::_1, cute::C<0>>>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::C<32>, cute::C<16>>, cute::_2>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::tuple<cute::C<4194304>, cute::C<1>>, cute::C<32>>, cute::C<0>, cute::C<0>>>, DstEngine=cute::ArrayEngine<float, 0ULL>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(408): error: static assertion failed with "Expected dst to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(dst)) == coalesce(upcast<sizeof_bits<DstType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected dst to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::STORE::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x, TS=cute::ViewEngine<const float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>, TD=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x>, CopyInternalType=float, SEngine=cute::ViewEngine<const float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x>, CopyInternalType=float, SEngine=cute::ViewEngine<const float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x, float>, SrcEngine=cute::ArrayEngine<float, 0ULL>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>, cute::C<0>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_2>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::_2, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::_4, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>>, SrcEngine=cute::ArrayEngine<float, 0ULL>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>, cute::C<0>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_2>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(408): error: static assertion failed with "Expected dst to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(dst)) == coalesce(upcast<sizeof_bits<DstType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected dst to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::STORE::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x, TS=cute::ViewEngine<uint32_t *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>, TD=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x>, CopyInternalType=float, SEngine=cute::ViewEngine<uint32_t *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x>, CopyInternalType=float, SEngine=cute::ViewEngine<uint32_t *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x, float>, SrcEngine=cute::ViewEngine<uint32_t *>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>, cute::tuple<cute::_0, int32_t>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>, cute::tuple<cute::C<32>, cute::C<0>>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::tuple<cute::_4, cute::_256>, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_16, cute::C<1>>>, SrcEngine=cute::ViewEngine<uint32_t *>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>, cute::tuple<cute::_0, int32_t>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>, cute::tuple<cute::C<32>, cute::C<0>>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>>>]" at line 514 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            [ 2 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp(522): error: static assertion failed with "The memory pointed to by AtomTVLayout does not exist in the DataLayout."
    static_assert(decltype(coalesce(composition(data_layout, layout<1>(layout_tv_data))) == coalesce(layout<1>(atom_tv_layout)))::value,"The memory pointed to by AtomTVLayout does not exist in the DataLayout.");
    ^
          detected during:
            instantiation of "auto cute::make_cotiled_copy(const cute::Copy_Atom<Args...> &, const AtomTVLayout &, const DataLayout &) [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x, float>, AtomTVLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::_2, cute::C<32>>>, cute::tuple<cute::tuple<cute::_0, cute::C<2097152>>, cute::tuple<cute::_1, cute::C<65536>>>>, DataLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 272 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const cute::Copy_Atom<CopyOp, CopyT> &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x, CopyT=float, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 282 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const CopyOp &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 991 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp(522): error: static assertion failed with "The memory pointed to by AtomTVLayout does not exist in the DataLayout."
    static_assert(decltype(coalesce(composition(data_layout, layout<1>(layout_tv_data))) == coalesce(layout<1>(atom_tv_layout)))::value,"The memory pointed to by AtomTVLayout does not exist in the DataLayout.");
    ^
          detected during:
            instantiation of "auto cute::make_cotiled_copy(const cute::Copy_Atom<Args...> &, const AtomTVLayout &, const DataLayout &) [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, AtomTVLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::C<16>, cute::C<32>>>, cute::tuple<cute::tuple<cute::_0, cute::C<2097152>>, cute::tuple<cute::_1, cute::C<65536>>>>, DataLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_16>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 272 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const cute::Copy_Atom<CopyOp, CopyT> &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, CopyT=float, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_16>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 282 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const CopyOp &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_16>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 904 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1027 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp(522): error: static assertion failed with "The memory pointed to by AtomTVLayout does not exist in the DataLayout."
    static_assert(decltype(coalesce(composition(data_layout, layout<1>(layout_tv_data))) == coalesce(layout<1>(atom_tv_layout)))::value,"The memory pointed to by AtomTVLayout does not exist in the DataLayout.");
    ^
          detected during:
            instantiation of "auto cute::make_cotiled_copy(const cute::Copy_Atom<Args...> &, const AtomTVLayout &, const DataLayout &) [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, float>, AtomTVLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::C<16>, cute::C<32>>>, cute::tuple<cute::tuple<cute::_0, cute::C<2097152>>, cute::tuple<cute::_1, cute::C<65536>>>>, DataLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_16>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 272 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const cute::Copy_Atom<CopyOp, CopyT> &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, CopyT=float, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_16>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 282 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const CopyOp &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_16>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 906 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1027 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(913): error: expression must have a constant value
      static_assert(shape(tTMEM_STOREcO) == shape(tTMEM_LOADcO));
                    ^
C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(536): note #2701-D: attempt to access run-time storage
    return shape<Is...>(tensor.layout());
                       ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1027
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(370): error: static assertion failed with "Dynamic owning tensors not supported"
        static_assert((is_static<Arg0>::value && ... && is_static<Args>::value),
        ^
          detected during:
            instantiation of "auto cute::MakeTensor<T>::operator()(const Arg0 &, const Args &...) const [with T=float, Arg0=cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::C<1>>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::C<8>>, Args=<>]" at line 401
            instantiation of "auto cute::make_tensor<T,Args...>(const Args &...) [with T=float, Args=<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::C<1>>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::C<8>>>]" at line 917 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1027 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1077): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                       static_assert(decltype(((rest_stride % curr_shape) == Int<0>{}) || (rest_stride < curr_shape))::value,"Stride Divisibility Condition");
                                     ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::_2, RStride=cute::_1]" at line 1038
            [ 18 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::_2, RStride=cute::_1]" at line 1038
            [ 18 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::_2, RStride=cute::_1]" at line 1038
            [ 18 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1077): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                       static_assert(decltype(((rest_stride % curr_shape) == Int<0>{}) || (rest_stride < curr_shape))::value,"Stride Divisibility Condition");
                                     ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::_8, RStride=cute::_2]" at line 1038
            [ 18 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::_8, RStride=cute::_2]" at line 1038
            [ 18 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::_8, RStride=cute::_2]" at line 1038
            [ 18 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1077): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                       static_assert(decltype(((rest_stride % curr_shape) == Int<0>{}) || (rest_stride < curr_shape))::value,"Stride Divisibility Condition");
                                     ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::C<0>, RStride=cute::_16]" at line 1038
            [ 14 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::C<0>, RStride=cute::_16]" at line 1038
            [ 14 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::C<0>, RStride=cute::_16]" at line 1038
            [ 14 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1213): error: static assertion failed with "Non-injective Layout detected in complement."
      static_assert(! is_constant<0, decltype(new_shape)>::value, "Non-injective Layout detected in complement.");
      ^
          detected during:
            instantiation of "auto cute::detail::complement(const Shape &, const Stride &, const CoTarget &) [with Shape=cute::tuple<cute::C<8>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_8, cute::_8, cute::_2>]" at line 1237
            instantiation of "auto cute::complement(const cute::Layout<Shape, Stride> &, const CoTarget &) [with Shape=cute::tuple<cute::C<8>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_8, cute::_8, cute::_2>]" at line 1578
            instantiation of "auto cute::logical_divide(const cute::Layout<LShape, LStride> &, const cute::Layout<TShape, TStride> &) [with LShape=cute::tuple<cute::_8, cute::_8, cute::_2>, LStride=cute::tuple<cute::_64, cute::C<1024>, cute::C<1>>, TShape=cute::tuple<cute::C<8>, cute::C<32>>, TStride=cute::tuple<cute::_16, cute::_1>]" at line 1589
            instantiation of function "lambda [](const auto &, const auto &)->auto [with <auto-1>=cute::Layout<cute::tuple<cute::_8, cute::_8, cute::_2>, cute::tuple<cute::_64, cute::C<1024>, cute::C<1>>>, <auto-2>=cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>]" at line 743
            instantiation of "auto cute::detail::transform_layout(const Tuple0 &, const Tuple1 &, F &&, cute::seq<I...>, cute::seq<I0...>, cute::seq<I1...>) [with Tuple0=cute::Layout<cute::tuple<cute::tuple<cute::_8, cute::_8, cute::_2>, cute::_16, cute::tuple<cute::_2, cute::_2>>, cute::tuple<cute::tuple<cute::_64, cute::C<1024>, cute::C<1>>, cute::_2, cute::tuple<cute::_32, cute::_512>>>, Tuple1=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_8, cute::C<1>>>, F=lambda [](const auto &, const auto &)->auto &, I=<0, 1>, I0=<2>, I1=<>]" at line 764
            [ 8 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<4>>, <auto-2>=cute::integral_constant<int, 1>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<4>>, X=cute::integral_constant<int, 1>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0, 1>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_8, cute::_8, cute::_2>, LStride=cute::tuple<cute::_64, cute::C<1024>, cute::C<1>>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 16 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<4>>, <auto-2>=cute::integral_constant<int, 1>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<4>>, X=cute::integral_constant<int, 1>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0, 1>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_8, cute::_8, cute::_2>, LStride=cute::tuple<cute::_64, cute::C<1024>, cute::C<1>>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 16 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(357): error: static assertion failed with "Expected src to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(src)) == coalesce(upcast<sizeof_bits<SrcType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected src to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::LOAD::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x, TS=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>, TD=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x, float>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_2>>, DstEngine=cute::ArrayEngine<float, 0ULL>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>, cute::C<0>>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::_2, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::_4, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_2>>, DstEngine=cute::ArrayEngine<float, 0ULL>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>, cute::C<0>>>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(357): error: static assertion failed with "Expected src to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(src)) == coalesce(upcast<sizeof_bits<SrcType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected src to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::LOAD::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, TS=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, TD=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>, DstEngine=cute::ViewEngine<float *>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::tuple<cute::_4, cute::_256>, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_8, cute::C<1>>>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>, DstEngine=cute::ViewEngine<float *>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(366): error: static assertion failed with "In CopyAtom, dst layout doesn't vectorize into registers. This dst layout is incompatible with this CopyOp."
    static_assert(decltype(size(rD) == Int<RegNumDst>{})::value,"In CopyAtom, dst layout doesn't vectorize into registers. This dst layout is incompatible with this CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::LOAD::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, TS=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, TD=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>, DstEngine=cute::ViewEngine<float *>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::tuple<cute::_4, cute::_256>, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_8, cute::C<1>>>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>, DstEngine=cute::ViewEngine<float *>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(404): error: static assertion failed with "In CopyAtom, src layout doesn't vectorize into registers. This src layout is incompatible with this tiled copy."
    static_assert(decltype(size(rS) == Int<RegNumSrc>{})::value,"In CopyAtom, src layout doesn't vectorize into registers. This src layout is incompatible with this tiled copy.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::STORE::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, TS=cute::ViewEngine<float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>, TD=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, float>, SrcEngine=cute::ViewEngine<float *>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::tuple<cute::_4, cute::_256>, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_8, cute::C<1>>>, SrcEngine=cute::ViewEngine<float *>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(408): error: static assertion failed with "Expected dst to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(dst)) == coalesce(upcast<sizeof_bits<DstType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected dst to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::STORE::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, TS=cute::ViewEngine<float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>, TD=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, float>, SrcEngine=cute::ViewEngine<float *>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::tuple<cute::_4, cute::_256>, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_8, cute::C<1>>>, SrcEngine=cute::ViewEngine<float *>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(357): error: static assertion failed with "Expected src to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(src)) == coalesce(upcast<sizeof_bits<SrcType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected src to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::LOAD::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, TS=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, TD=cute::ArrayEngine<float, 16ULL>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::C<1>>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ArrayEngine<float, 16ULL>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::C<1>>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>]" at line 181 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DstEngine=cute::ArrayEngine<float, 16ULL>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::C<1>>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::tuple<cute::_4, cute::_256>, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_8, cute::C<1>>>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DstEngine=cute::ArrayEngine<float, 16ULL>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::C<1>>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(684): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/pipeline/sm90_pipeline.hpp(333): warning #177-D: variable "thread_idx" was declared but never referenced
      int thread_idx = threadIdx.x;
          ^
          detected during:
            instantiation of "cutlass::PipelineTmaAsync<Stages_>::PipelineTmaAsync(cutlass::PipelineTmaAsync<Stages_>::SharedStorage &, cutlass::PipelineTmaAsync<Stages_>::Params, ClusterShape, InitBarriers, InitMasks) [with Stages_=3, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, InitBarriers=cute::false_type, InitMasks=cute::false_type]" at line 563 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/pipeline/sm100_pipeline.hpp
            instantiation of "cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::PipelineTmaUmmaAsync(cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::SharedStorage &, cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::Params, ClusterShape, InitBarriers, InitMasks) [with Stages_=3, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, AtomThrShape_MNK_=cute::tuple<cute::_1, cute::_1, cute::_1>, InitBarriers=cute::true_type, InitMasks=cute::false_type]" at line 327 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/pipeline/sm100_pipeline.hpp(538): warning #177-D: variable "cluster_layout" was declared but never referenced
        auto cluster_layout = make_layout(cluster_shape);
             ^
          detected during:
            instantiation of "void cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::init_masks(ClusterShape, dim3) [with Stages_=3, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, AtomThrShape_MNK_=cute::tuple<cute::_1, cute::_1, cute::_1>]" at line 421 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(902): error: expression must have a constant value
      static_assert(shape(tTMEM_STOREcO) == shape(tTMEM_LOADcO));
                    ^
C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(536): note #2701-D: attempt to access run-time storage
    return shape<Is...>(tensor.layout());
                       ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1016
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(684): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(913): error: expression must have a constant value
      static_assert(shape(tTMEM_STOREcO) == shape(tTMEM_LOADcO));
                    ^
C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(536): note #2701-D: attempt to access run-time storage
    return shape<Is...>(tensor.layout());
                       ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1027
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(684): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(902): error: expression must have a constant value
      static_assert(shape(tTMEM_STOREcO) == shape(tTMEM_LOADcO));
                    ^
C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(536): note #2701-D: attempt to access run-time storage
    return shape<Is...>(tensor.layout());
                       ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1016
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::true_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, TileScheduler=cutlass::fmha::kernel::PersistentTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::true_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::true_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, TileScheduler=cutlass::fmha::kernel::PersistentTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::true_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, TileScheduler=cutlass::fmha::kernel::PersistentTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, TileScheduler=cutlass::fmha::kernel::PersistentTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::PersistentTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::PersistentTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

51 errors detected in the compilation of "C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/sm100/prefill/dense/fmha_cutlass_fwd_sm100.cu".
C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/pipeline/sm90_pipeline.hpp(333): warning #177-D: variable "thread_idx" was declared but never referenced
      int thread_idx = threadIdx.x;
          ^
          detected during:
            instantiation of "cutlass::PipelineTmaAsync<Stages_>::PipelineTmaAsync(cutlass::PipelineTmaAsync<Stages_>::SharedStorage &, cutlass::PipelineTmaAsync<Stages_>::Params, ClusterShape, InitBarriers, InitMasks) [with Stages_=2, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, InitBarriers=cute::false_type, InitMasks=cute::false_type]" at line 563 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/pipeline/sm100_pipeline.hpp
            instantiation of "cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::PipelineTmaUmmaAsync(cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::SharedStorage &, cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::Params, ClusterShape, InitBarriers, InitMasks) [with Stages_=2, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, AtomThrShape_MNK_=cute::tuple<cute::_1, cute::_1, cute::_1>, InitBarriers=cute::true_type, InitMasks=cute::false_type]" at line 313 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/pipeline/sm100_pipeline.hpp(538): warning #177-D: variable "cluster_layout" was declared but never referenced
        auto cluster_layout = make_layout(cluster_shape);
             ^
          detected during:
            instantiation of "void cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::init_masks(ClusterShape, dim3) [with Stages_=2, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, AtomThrShape_MNK_=cute::tuple<cute::_1, cute::_1, cute::_1>]" at line 420 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective\../common/pipeline_mla.hpp(114): warning #177-D: variable "cluster_layout" was declared but never referenced
        auto cluster_layout = make_layout(cluster_shape);
             ^
          detected during:
            instantiation of "void cutlass::PipelineTmaAsyncMla<Stages_, ClusterShape, AtomThrShape_MNK_>::init_masks(ClusterShape, dim3) [with Stages_=2, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, AtomThrShape_MNK_=cute::tuple<cute::_1, cute::_1, cute::_1>]" at line 421 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp(522): error: static assertion failed with "The memory pointed to by AtomTVLayout does not exist in the DataLayout."
    static_assert(decltype(coalesce(composition(data_layout, layout<1>(layout_tv_data))) == coalesce(layout<1>(atom_tv_layout)))::value,"The memory pointed to by AtomTVLayout does not exist in the DataLayout.");
    ^
          detected during:
            instantiation of "auto cute::make_cotiled_copy(const cute::Copy_Atom<Args...> &, const AtomTVLayout &, const DataLayout &) [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x, float>, AtomTVLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::C<32>, cute::C<32>>>, cute::tuple<cute::tuple<cute::_0, cute::C<2097152>>, cute::tuple<cute::_1, cute::C<65536>>>>, DataLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<64>>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>>, cute::_1>, cute::C<0>, cute::C<0>>>]" at line 272 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const cute::Copy_Atom<CopyOp, CopyT> &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x, CopyT=float, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<64>>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>>, cute::_1>, cute::C<0>, cute::C<0>>>]" at line 282 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const CopyOp &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<64>>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>>, cute::_1>, cute::C<0>, cute::C<0>>>]" at line 567 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1213): error: static assertion failed with "Non-injective Layout detected in complement."
      static_assert(! is_constant<0, decltype(new_shape)>::value, "Non-injective Layout detected in complement.");
      ^
          detected during:
            instantiation of "auto cute::detail::complement(const Shape &, const Stride &, const CoTarget &) [with Shape=cute::tuple<cute::C<128>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_16, cute::_4, cute::_64>]" at line 1237
            instantiation of "auto cute::complement(const cute::Layout<Shape, Stride> &, const CoTarget &) [with Shape=cute::tuple<cute::C<128>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_16, cute::_4, cute::_64>]" at line 1578
            instantiation of "auto cute::logical_divide(const cute::Layout<LShape, LStride> &, const cute::Layout<TShape, TStride> &) [with LShape=cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<64>>, LStride=cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>>, cute::_1>, TShape=cute::tuple<cute::C<128>, cute::C<32>>, TStride=cute::tuple<cute::_16, cute::_1>]" at line 1589
            instantiation of function "lambda [](const auto &, const auto &)->auto [with <auto-1>=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<64>>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>>, cute::_1>>, <auto-2>=cute::Layout<cute::tuple<cute::C<128>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>]" at line 743
            instantiation of "auto cute::detail::transform_layout(const Tuple0 &, const Tuple1 &, F &&, cute::seq<I...>, cute::seq<I0...>, cute::seq<I1...>) [with Tuple0=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<64>>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>>, cute::_1>, cute::C<0>, cute::C<0>>>, Tuple1=cute::tuple<cute::Layout<cute::tuple<cute::C<128>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>, cute::Layout<cute::_1, cute::C<0>>>, F=lambda [](const auto &, const auto &)->auto &, I=<0, 1, 2>, I0=<>, I1=<>]" at line 764
            [ 8 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, <auto-2>=cute::integral_constant<int, 1>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, X=cute::integral_constant<int, 1>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0, 1>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_16, cute::_4, cute::_64>, LStride=cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 20 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, <auto-2>=cute::integral_constant<int, 1>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, X=cute::integral_constant<int, 1>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0, 1>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_16, cute::_4, cute::_64>, LStride=cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 20 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1213): error: static assertion failed with "Non-injective Layout detected in complement."
      static_assert(! is_constant<0, decltype(new_shape)>::value, "Non-injective Layout detected in complement.");
      ^
          detected during:
            instantiation of "auto cute::detail::complement(const Shape &, const Stride &, const CoTarget &) [with Shape=cute::tuple<cute::C<128>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::C<64>, cute::C<64>>]" at line 1237
            instantiation of "auto cute::complement(const cute::Layout<Shape, Stride> &, const CoTarget &) [with Shape=cute::tuple<cute::C<128>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::C<64>, cute::C<64>>]" at line 1578
            instantiation of "auto cute::logical_divide(const cute::Layout<LShape, LStride> &, const cute::Layout<TShape, TStride> &) [with LShape=cute::tuple<cute::C<64>, cute::C<64>>, LStride=cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, TShape=cute::tuple<cute::C<128>, cute::C<32>>, TStride=cute::tuple<cute::_16, cute::_1>]" at line 1589
            instantiation of function "lambda [](const auto &, const auto &)->auto [with <auto-1>=cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>, <auto-2>=cute::Layout<cute::tuple<cute::C<128>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>]" at line 743
            instantiation of "auto cute::detail::transform_layout(const Tuple0 &, const Tuple1 &, F &&, cute::seq<I...>, cute::seq<I0...>, cute::seq<I1...>) [with Tuple0=cute::Layout<cute::tuple<cute::tuple<cute::C<64>, cute::C<64>>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::C<0>, cute::C<0>>>, Tuple1=cute::tuple<cute::Layout<cute::tuple<cute::C<128>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>, cute::Layout<cute::_1, cute::C<0>>>, F=lambda [](const auto &, const auto &)->auto &, I=<0, 1, 2>, I0=<>, I1=<>]" at line 764
            [ 8 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::C<64>, cute::C<64>>, LStride=cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 20 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::C<64>, cute::C<64>>, LStride=cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 20 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp(522): error: static assertion failed with "The memory pointed to by AtomTVLayout does not exist in the DataLayout."
    static_assert(decltype(coalesce(composition(data_layout, layout<1>(layout_tv_data))) == coalesce(layout<1>(atom_tv_layout)))::value,"The memory pointed to by AtomTVLayout does not exist in the DataLayout.");
    ^
          detected during:
            instantiation of "auto cute::make_cotiled_copy(const cute::Copy_Atom<Args...> &, const AtomTVLayout &, const DataLayout &) [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x, float>, AtomTVLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::_2, cute::C<32>>>, cute::tuple<cute::tuple<cute::_0, cute::C<2097152>>, cute::tuple<cute::_1, cute::C<65536>>>>, DataLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 272 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const cute::Copy_Atom<CopyOp, CopyT> &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x, CopyT=float, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 282 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const CopyOp &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 573 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1213): error: static assertion failed with "Non-injective Layout detected in complement."
      static_assert(! is_constant<0, decltype(new_shape)>::value, "Non-injective Layout detected in complement.");
      ^
          detected during:
            instantiation of "auto cute::detail::complement(const Shape &, const Stride &, const CoTarget &) [with Shape=cute::tuple<cute::C<8>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_16, cute::_4, cute::C<2>>]" at line 1237
            instantiation of "auto cute::complement(const cute::Layout<Shape, Stride> &, const CoTarget &) [with Shape=cute::tuple<cute::C<8>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_16, cute::_4, cute::C<2>>]" at line 1578
            instantiation of "auto cute::logical_divide(const cute::Layout<LShape, LStride> &, const cute::Layout<TShape, TStride> &) [with LShape=cute::tuple<cute::_16, cute::_4, cute::C<2>>, LStride=cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, TShape=cute::tuple<cute::C<8>, cute::C<32>>, TStride=cute::tuple<cute::_16, cute::_1>]" at line 1589
            instantiation of function "lambda [](const auto &, const auto &)->auto [with <auto-1>=cute::Layout<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>>, <auto-2>=cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>]" at line 743
            instantiation of "auto cute::detail::transform_layout(const Tuple0 &, const Tuple1 &, F &&, cute::seq<I...>, cute::seq<I0...>, cute::seq<I1...>) [with Tuple0=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>, Tuple1=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>>, F=lambda [](const auto &, const auto &)->auto &, I=<0, 1>, I0=<>, I1=<>]" at line 764
            [ 8 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, <auto-2>=cute::integral_constant<int, 1>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, X=cute::integral_constant<int, 1>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0, 1>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_16, cute::_4, cute::C<2>>, LStride=cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 16 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, <auto-2>=cute::integral_constant<int, 1>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<2>>, X=cute::integral_constant<int, 1>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0, 1>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_16, cute::_4, cute::C<2>>, LStride=cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 16 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1213): error: static assertion failed with "Non-injective Layout detected in complement."
      static_assert(! is_constant<0, decltype(new_shape)>::value, "Non-injective Layout detected in complement.");
      ^
          detected during:
            instantiation of "auto cute::detail::complement(const Shape &, const Stride &, const CoTarget &) [with Shape=cute::tuple<cute::C<8>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_64, cute::_2>]" at line 1237
            instantiation of "auto cute::complement(const cute::Layout<Shape, Stride> &, const CoTarget &) [with Shape=cute::tuple<cute::C<8>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_64, cute::_2>]" at line 1578
            instantiation of "auto cute::logical_divide(const cute::Layout<LShape, LStride> &, const cute::Layout<TShape, TStride> &) [with LShape=cute::tuple<cute::_64, cute::_2>, LStride=cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, TShape=cute::tuple<cute::C<8>, cute::C<32>>, TStride=cute::tuple<cute::_16, cute::_1>]" at line 1589
            instantiation of function "lambda [](const auto &, const auto &)->auto [with <auto-1>=cute::Layout<cute::tuple<cute::_64, cute::_2>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>, <auto-2>=cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>]" at line 743
            instantiation of "auto cute::detail::transform_layout(const Tuple0 &, const Tuple1 &, F &&, cute::seq<I...>, cute::seq<I0...>, cute::seq<I1...>) [with Tuple0=cute::Layout<cute::tuple<cute::tuple<cute::_64, cute::_2>, cute::_2>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<2>, 1>>>, Tuple1=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>>, F=lambda [](const auto &, const auto &)->auto &, I=<0, 1>, I0=<>, I1=<>]" at line 764
            [ 8 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_64, cute::_2>, LStride=cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 16 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_64, cute::_2>, LStride=cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 16 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp(522): error: static assertion failed with "The memory pointed to by AtomTVLayout does not exist in the DataLayout."
    static_assert(decltype(coalesce(composition(data_layout, layout<1>(layout_tv_data))) == coalesce(layout<1>(atom_tv_layout)))::value,"The memory pointed to by AtomTVLayout does not exist in the DataLayout.");
    ^
          detected during:
            instantiation of "auto cute::make_cotiled_copy(const cute::Copy_Atom<Args...> &, const AtomTVLayout &, const DataLayout &) [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x, float>, AtomTVLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::C<32>, cute::C<32>>>, cute::tuple<cute::tuple<cute::_0, cute::C<2097152>>, cute::tuple<cute::_1, cute::C<65536>>>>, DataLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::C<32>>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 272 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const cute::Copy_Atom<CopyOp, CopyT> &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x, CopyT=float, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::C<32>>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 282 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const CopyOp &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::C<32>>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 579 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(370): error: static assertion failed with "Dynamic owning tensors not supported"
        static_assert((is_static<Arg0>::value && ... && is_static<Args>::value),
        ^
          detected during:
            instantiation of "auto cute::MakeTensor<T>::operator()(const Arg0 &, const Args &...) const [with T=float, Arg0=cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, Args=<>]" at line 401
            instantiation of "auto cute::make_tensor<T,Args...>(const Args &...) [with T=float, Args=<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>>]" at line 590 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(370): error: static assertion failed with "Dynamic owning tensors not supported"
        static_assert((is_static<Arg0>::value && ... && is_static<Args>::value),
        ^
          detected during:
            instantiation of "auto cute::MakeTensor<T>::operator()(const Arg0 &, const Args &...) const [with T=float, Arg0=cute::tuple<cute::tuple<cute::_2, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, Args=<>]" at line 401
            instantiation of "auto cute::make_tensor<T,Args...>(const Args &...) [with T=float, Args=<cute::tuple<cute::tuple<cute::_2, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>>]" at line 620 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(370): error: static assertion failed with "Dynamic owning tensors not supported"
        static_assert((is_static<Arg0>::value && ... && is_static<Args>::value),
        ^
          detected during:
            instantiation of "auto cute::MakeTensor<T>::operator()(const Arg0 &, const Args &...) const [with T=uint32_t, Arg0=cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, Args=<>]" at line 401
            instantiation of "auto cute::make_tensor<T,Args...>(const Args &...) [with T=uint32_t, Args=<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>>]" at line 636 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(684): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(357): error: static assertion failed with "Expected src to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(src)) == coalesce(upcast<sizeof_bits<SrcType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected src to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::LOAD::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x, TS=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::C<32>, cute::C<16>>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>, TD=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::C<32>, cute::C<16>>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::C<32>, cute::C<16>>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x, float>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::C<32>, cute::C<16>>, cute::_2>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::tuple<cute::C<4194304>, cute::C<1>>, cute::C<32>>, cute::C<0>, cute::C<0>>>, DstEngine=cute::ArrayEngine<float, 0ULL>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b32x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::C<32>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::_4, cute::tuple<cute::_128, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<128>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>, cute::Layout<cute::_1, cute::C<0>>>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::C<32>, cute::C<16>>, cute::_2>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::tuple<cute::C<4194304>, cute::C<1>>, cute::C<32>>, cute::C<0>, cute::C<0>>>, DstEngine=cute::ArrayEngine<float, 0ULL>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(408): error: static assertion failed with "Expected dst to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(dst)) == coalesce(upcast<sizeof_bits<DstType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected dst to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::STORE::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x, TS=cute::ViewEngine<const float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>, TD=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x>, CopyInternalType=float, SEngine=cute::ViewEngine<const float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x>, CopyInternalType=float, SEngine=cute::ViewEngine<const float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x, float>, SrcEngine=cute::ArrayEngine<float, 0ULL>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>, cute::C<0>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_2>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b2x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::_2, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::_4, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>>, SrcEngine=cute::ArrayEngine<float, 0ULL>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>, cute::C<0>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_2>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(408): error: static assertion failed with "Expected dst to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(dst)) == coalesce(upcast<sizeof_bits<DstType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected dst to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::STORE::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x, TS=cute::ViewEngine<uint32_t *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>, TD=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x>, CopyInternalType=float, SEngine=cute::ViewEngine<uint32_t *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x>, CopyInternalType=float, SEngine=cute::ViewEngine<uint32_t *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x, float>, SrcEngine=cute::ViewEngine<uint32_t *>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>, cute::tuple<cute::_0, int32_t>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>, cute::tuple<cute::C<32>, cute::C<0>>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b32x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::tuple<cute::_4, cute::_256>, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_16, cute::C<1>>>, SrcEngine=cute::ViewEngine<uint32_t *>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_1>, cute::tuple<cute::_0, int32_t>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>, cute::tuple<cute::C<32>, cute::C<0>>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>>>]" at line 514 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            [ 2 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp(522): error: static assertion failed with "The memory pointed to by AtomTVLayout does not exist in the DataLayout."
    static_assert(decltype(coalesce(composition(data_layout, layout<1>(layout_tv_data))) == coalesce(layout<1>(atom_tv_layout)))::value,"The memory pointed to by AtomTVLayout does not exist in the DataLayout.");
    ^
          detected during:
            instantiation of "auto cute::make_cotiled_copy(const cute::Copy_Atom<Args...> &, const AtomTVLayout &, const DataLayout &) [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x, float>, AtomTVLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::_2, cute::C<32>>>, cute::tuple<cute::tuple<cute::_0, cute::C<2097152>>, cute::tuple<cute::_1, cute::C<65536>>>>, DataLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 272 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const cute::Copy_Atom<CopyOp, CopyT> &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x, CopyT=float, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 282 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const CopyOp &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_2>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 991 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp(522): error: static assertion failed with "The memory pointed to by AtomTVLayout does not exist in the DataLayout."
    static_assert(decltype(coalesce(composition(data_layout, layout<1>(layout_tv_data))) == coalesce(layout<1>(atom_tv_layout)))::value,"The memory pointed to by AtomTVLayout does not exist in the DataLayout.");
    ^
          detected during:
            instantiation of "auto cute::make_cotiled_copy(const cute::Copy_Atom<Args...> &, const AtomTVLayout &, const DataLayout &) [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, AtomTVLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::C<16>, cute::C<32>>>, cute::tuple<cute::tuple<cute::_0, cute::C<2097152>>, cute::tuple<cute::_1, cute::C<65536>>>>, DataLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_16>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 272 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const cute::Copy_Atom<CopyOp, CopyT> &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, CopyT=float, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_16>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 282 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const CopyOp &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_16>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 904 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1027 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp(522): error: static assertion failed with "The memory pointed to by AtomTVLayout does not exist in the DataLayout."
    static_assert(decltype(coalesce(composition(data_layout, layout<1>(layout_tv_data))) == coalesce(layout<1>(atom_tv_layout)))::value,"The memory pointed to by AtomTVLayout does not exist in the DataLayout.");
    ^
          detected during:
            instantiation of "auto cute::make_cotiled_copy(const cute::Copy_Atom<Args...> &, const AtomTVLayout &, const DataLayout &) [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, float>, AtomTVLayout=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::C<16>, cute::C<32>>>, cute::tuple<cute::tuple<cute::_0, cute::C<2097152>>, cute::tuple<cute::_1, cute::C<65536>>>>, DataLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_16>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 272 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const cute::Copy_Atom<CopyOp, CopyT> &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, CopyT=float, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_16>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 282 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp
            instantiation of "auto cute::make_tmem_copy(const CopyOp &, const cute::Tensor<TEngine, TLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, TEngine=cute::ViewEngine<cute::tmem_ptr<float>>, TLayout=cute::Layout<cute::tuple<cute::tuple<cute::_16, cute::_4, cute::C<2>>, cute::_16>, cute::tuple<cute::tuple<cute::C<65536>, cute::C<2097152>, cute::_1>, cute::_2>>]" at line 906 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1027 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(913): error: expression must have a constant value
      static_assert(shape(tTMEM_STOREcO) == shape(tTMEM_LOADcO));
                    ^
C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(536): note #2701-D: attempt to access run-time storage
    return shape<Is...>(tensor.layout());
                       ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1027
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(370): error: static assertion failed with "Dynamic owning tensors not supported"
        static_assert((is_static<Arg0>::value && ... && is_static<Args>::value),
        ^
          detected during:
            instantiation of "auto cute::MakeTensor<T>::operator()(const Arg0 &, const Args &...) const [with T=float, Arg0=cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::C<1>>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::C<8>>, Args=<>]" at line 401
            instantiation of "auto cute::make_tensor<T,Args...>(const Args &...) [with T=float, Args=<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::C<1>>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::C<8>>>]" at line 917 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1027 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1077): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                       static_assert(decltype(((rest_stride % curr_shape) == Int<0>{}) || (rest_stride < curr_shape))::value,"Stride Divisibility Condition");
                                     ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::_2, RStride=cute::_1]" at line 1038
            [ 18 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::_2, RStride=cute::_1]" at line 1038
            [ 18 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_2, cute::_1>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::_2, RStride=cute::_1]" at line 1038
            [ 18 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1077): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                       static_assert(decltype(((rest_stride % curr_shape) == Int<0>{}) || (rest_stride < curr_shape))::value,"Stride Divisibility Condition");
                                     ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::_8, RStride=cute::_2]" at line 1038
            [ 18 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::_8, RStride=cute::_2]" at line 1038
            [ 18 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::_8, cute::C<2>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::_8, RStride=cute::_2]" at line 1038
            [ 18 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1077): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                       static_assert(decltype(((rest_stride % curr_shape) == Int<0>{}) || (rest_stride < curr_shape))::value,"Stride Divisibility Condition");
                                     ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::C<0>, RStride=cute::_16]" at line 1038
            [ 14 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::C<0>, RStride=cute::_16]" at line 1038
            [ 14 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, <auto-2>=cute::integral_constant<int, 0>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, X=cute::integral_constant<int, 0>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, F=lambda [](const auto &, auto)->auto &, Is=<0>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::_16>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_0, int32_t>, LStride=cute::tuple<cute::_1, cute::_0>, RShape=cute::C<0>, RStride=cute::_16]" at line 1038
            [ 14 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1213): error: static assertion failed with "Non-injective Layout detected in complement."
      static_assert(! is_constant<0, decltype(new_shape)>::value, "Non-injective Layout detected in complement.");
      ^
          detected during:
            instantiation of "auto cute::detail::complement(const Shape &, const Stride &, const CoTarget &) [with Shape=cute::tuple<cute::C<8>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_8, cute::_8, cute::_2>]" at line 1237
            instantiation of "auto cute::complement(const cute::Layout<Shape, Stride> &, const CoTarget &) [with Shape=cute::tuple<cute::C<8>, cute::C<32>>, Stride=cute::tuple<cute::_16, cute::_1>, CoTarget=cute::tuple<cute::_8, cute::_8, cute::_2>]" at line 1578
            instantiation of "auto cute::logical_divide(const cute::Layout<LShape, LStride> &, const cute::Layout<TShape, TStride> &) [with LShape=cute::tuple<cute::_8, cute::_8, cute::_2>, LStride=cute::tuple<cute::_64, cute::C<1024>, cute::C<1>>, TShape=cute::tuple<cute::C<8>, cute::C<32>>, TStride=cute::tuple<cute::_16, cute::_1>]" at line 1589
            instantiation of function "lambda [](const auto &, const auto &)->auto [with <auto-1>=cute::Layout<cute::tuple<cute::_8, cute::_8, cute::_2>, cute::tuple<cute::_64, cute::C<1024>, cute::C<1>>>, <auto-2>=cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>]" at line 743
            instantiation of "auto cute::detail::transform_layout(const Tuple0 &, const Tuple1 &, F &&, cute::seq<I...>, cute::seq<I0...>, cute::seq<I1...>) [with Tuple0=cute::Layout<cute::tuple<cute::tuple<cute::_8, cute::_8, cute::_2>, cute::_16, cute::tuple<cute::_2, cute::_2>>, cute::tuple<cute::tuple<cute::_64, cute::C<1024>, cute::C<1>>, cute::_2, cute::tuple<cute::_32, cute::_512>>>, Tuple1=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_8, cute::C<1>>>, F=lambda [](const auto &, const auto &)->auto &, I=<0, 1>, I0=<2>, I1=<>]" at line 764
            [ 8 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1101): error: result of decltype qualifier "__nv_bool" is not a class or enumeration
                         static_assert(decltype(((rest_shape % new_shape) == Int<0>{}))::value,"Shape Divisibility Condition");
                                       ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<4>>, <auto-2>=cute::integral_constant<int, 1>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<4>>, X=cute::integral_constant<int, 1>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0, 1>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_8, cute::_8, cute::_2>, LStride=cute::tuple<cute::_64, cute::C<1024>, cute::C<1>>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 16 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/layout.hpp(1109): warning #39-D: division by zero
                                               rest_shape / new_shape,
                                                          ^
          detected during:
            instantiation of function "lambda [](const auto &, auto)->auto [with <auto-1>=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<4>>, <auto-2>=cute::integral_constant<int, 1>]" at line 379 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::FoldAdaptor<Fn, Val>::operator|(X &&) [with Fn=lambda [](const auto &, auto)->auto &, Val=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<4>>, X=cute::integral_constant<int, 1>]" at line 391 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::detail::fold(T &&, const V &, F &&, cute::seq<Is...>) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto &, Is=<0, 1>]" at line 402 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/tuple_algorithms.hpp
            instantiation of "auto cute::fold(T &&, const V &, F &&) [with T=std::integer_sequence<int, 0, 1>, V=cute::tuple<cute::tuple<>, cute::tuple<>, cute::C<0>, cute::C<32>>, F=lambda [](const auto &, auto)->auto]" at line 1114
            instantiation of "auto cute::detail::composition_impl(const LShape &, const LStride &, const RShape &, const RStride &) [with LShape=cute::tuple<cute::_8, cute::_8, cute::_2>, LStride=cute::tuple<cute::_64, cute::C<1024>, cute::C<1>>, RShape=cute::C<0>, RStride=cute::C<32>]" at line 1038
            [ 16 instantiation contexts not shown ]
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(357): error: static assertion failed with "Expected src to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(src)) == coalesce(upcast<sizeof_bits<SrcType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected src to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::LOAD::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x, TS=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>, TD=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>>, cute::tuple<cute::tuple<cute::_1, cute::_0>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x, float>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_2>>, DstEngine=cute::ArrayEngine<float, 0ULL>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>, cute::C<0>>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b2x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::_2, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::_4, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_1, cute::C<0>>>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::_16>, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::C<65536>>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_2>>, DstEngine=cute::ArrayEngine<float, 0ULL>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::_2, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>, cute::C<0>>>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(357): error: static assertion failed with "Expected src to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(src)) == coalesce(upcast<sizeof_bits<SrcType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected src to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::LOAD::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, TS=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, TD=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>, DstEngine=cute::ViewEngine<float *>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::tuple<cute::_4, cute::_256>, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_8, cute::C<1>>>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>, DstEngine=cute::ViewEngine<float *>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(366): error: static assertion failed with "In CopyAtom, dst layout doesn't vectorize into registers. This dst layout is incompatible with this CopyOp."
    static_assert(decltype(size(rD) == Int<RegNumDst>{})::value,"In CopyAtom, dst layout doesn't vectorize into registers. This dst layout is incompatible with this CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::LOAD::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, TS=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, TD=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ViewEngine<float *>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>, DstEngine=cute::ViewEngine<float *>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::tuple<cute::_4, cute::_256>, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_8, cute::C<1>>>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>, DstEngine=cute::ViewEngine<float *>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(404): error: static assertion failed with "In CopyAtom, src layout doesn't vectorize into registers. This src layout is incompatible with this tiled copy."
    static_assert(decltype(size(rS) == Int<RegNumSrc>{})::value,"In CopyAtom, src layout doesn't vectorize into registers. This src layout is incompatible with this tiled copy.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::STORE::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, TS=cute::ViewEngine<float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>, TD=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, float>, SrcEngine=cute::ViewEngine<float *>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::tuple<cute::_4, cute::_256>, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_8, cute::C<1>>>, SrcEngine=cute::ViewEngine<float *>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(408): error: static assertion failed with "Expected dst to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(dst)) == coalesce(upcast<sizeof_bits<DstType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected dst to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::STORE::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, TS=cute::ViewEngine<float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>, TD=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 124 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &&) const [with Args=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<float *>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>>>, DEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>]" at line 216 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, float>, SrcEngine=cute::ViewEngine<float *>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::STORE::SM100_TMEM_STORE_32dp32b16x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::tuple<cute::_4, cute::_256>, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_8, cute::C<1>>>, SrcEngine=cute::ViewEngine<float *>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_0, int32_t>, cute::tuple<cute::_0, int32_t>>, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, int>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::C<2>, cute::C<0>>>, cute::C<0>>, cute::tuple<cute::tuple<cute::_16, cute::C<0>>, cute::C<0>>, cute::C<0>>>, DstEngine=cute::ViewEngine<cute::tmem_ptr<float>>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>, cute::tuple<cute::_0, int32_t>, cute::_2>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>, cute::tuple<cute::C<4194304>, cute::C<1>>, cute::_16>>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_traits_sm100.hpp(357): error: static assertion failed with "Expected src to have the specific TMEM layout required by CopyOp."
    static_assert(decltype((coalesce(layout(src)) == coalesce(upcast<sizeof_bits<SrcType>::value>(typename Copy_Traits<CopyOp>::ValID{}))))::value,"Expected src to have the specific TMEM layout required by CopyOp.");
    ^
          detected during:
            instantiation of "void cute::SM100::TMEM::LOAD::copy_unpack(const cute::Copy_Traits<CopyOp> &, const cute::Tensor<TS, SLayout> &, cute::Tensor<TD, DLayout> &) [with CopyOp=cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, TS=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, TD=cute::ArrayEngine<float, 16ULL>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::C<1>>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>]" at line 103 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/atom/copy_atom.hpp
            instantiation of "void cute::Copy_Atom<cute::Copy_Traits<Args...>, CopyInternalType>::call(const cute::Tensor<SEngine, SLayout> &, cute::Tensor<DEngine, DLayout> &) const [with Args=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x>, CopyInternalType=float, SEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DEngine=cute::ArrayEngine<float, 16ULL>, DLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::C<1>>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>]" at line 181 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::Copy_Atom<CopyArgs...> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyArgs=<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DstEngine=cute::ArrayEngine<float, 16ULL>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::C<1>>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>]" at line 412 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/algorithm/copy.hpp
            instantiation of "void cute::copy(const cute::TiledCopy<CopyAtom, TV, Tiler> &, const cute::Tensor<SrcEngine, SrcLayout> &, cute::Tensor<DstEngine, DstLayout> &) [with CopyAtom=cute::Copy_Atom<cute::SM100::TMEM::LOAD::SM100_TMEM_LOAD_32dp32b16x, float>, TV=cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::tuple<cute::_16, cute::_2>>>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::tuple<cute::tuple<cute::_4, cute::_256>, cute::tuple<cute::_8, cute::_1>>>>, Tiler=cute::tuple<cute::Layout<cute::tuple<cute::C<8>, cute::C<32>>, cute::tuple<cute::_16, cute::_1>>, cute::Layout<cute::_8, cute::C<1>>>, SrcEngine=cute::ViewEngine<cute::tmem_ptr<float>>, SrcLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>, cute::_16, cute::_2>, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2, cute::C<65536>, cute::C<2097152>>, cute::C<0>>>>, DstEngine=cute::ArrayEngine<float, 16ULL>, DstLayout=cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_2, cute::C<8>>, cute::C<1>>>, cute::tuple<cute::tuple<cute::tuple<cute::_1, cute::_2>, cute::C<0>>>>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(684): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/pipeline/sm90_pipeline.hpp(333): warning #177-D: variable "thread_idx" was declared but never referenced
      int thread_idx = threadIdx.x;
          ^
          detected during:
            instantiation of "cutlass::PipelineTmaAsync<Stages_>::PipelineTmaAsync(cutlass::PipelineTmaAsync<Stages_>::SharedStorage &, cutlass::PipelineTmaAsync<Stages_>::Params, ClusterShape, InitBarriers, InitMasks) [with Stages_=3, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, InitBarriers=cute::false_type, InitMasks=cute::false_type]" at line 563 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/pipeline/sm100_pipeline.hpp
            instantiation of "cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::PipelineTmaUmmaAsync(cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::SharedStorage &, cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::Params, ClusterShape, InitBarriers, InitMasks) [with Stages_=3, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, AtomThrShape_MNK_=cute::tuple<cute::_1, cute::_1, cute::_1>, InitBarriers=cute::true_type, InitMasks=cute::false_type]" at line 327 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/pipeline/sm100_pipeline.hpp(538): warning #177-D: variable "cluster_layout" was declared but never referenced
        auto cluster_layout = make_layout(cluster_shape);
             ^
          detected during:
            instantiation of "void cutlass::PipelineTmaUmmaAsync<Stages_, ClusterShape, AtomThrShape_MNK_>::init_masks(ClusterShape, dim3) [with Stages_=3, ClusterShape=cute::tuple<cute::_1, cute::_1, cute::_1>, AtomThrShape_MNK_=cute::tuple<cute::_1, cute::_1, cute::_1>]" at line 421 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(902): error: expression must have a constant value
      static_assert(shape(tTMEM_STOREcO) == shape(tTMEM_LOADcO));
                    ^
C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(536): note #2701-D: attempt to access run-time storage
    return shape<Is...>(tensor.layout());
                       ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1016
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(272): warning #221-D: floating-point value does not fit in required floating-point type
            acc_qk(i) = -((float)(1e+300));
                          ^
          detected during:
            instantiation of "void cutlass::fmha::collective::CausalMask<kIsQBegin>::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with kIsQBegin=false, AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::CausalMask<false>, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::CausalMask<false>, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::CausalMask<false>, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::CausalMask<false>, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(684): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(913): error: expression must have a constant value
      static_assert(shape(tTMEM_STOREcO) == shape(tTMEM_LOADcO));
                    ^
C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(536): note #2701-D: attempt to access run-time storage
    return shape<Is...>(tensor.layout());
                       ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1027
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(684): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(902): error: expression must have a constant value
      static_assert(shape(tTMEM_STOREcO) == shape(tTMEM_LOADcO));
                    ^
C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cute/tensor_impl.hpp(536): note #2701-D: attempt to access run-time storage
    return shape<Is...>(tensor.layout());
                       ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_rescale(float, uint32_t) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type]" at line 1016
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineO &, cutlass::PipelineUmmaAsync<2, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 525 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(660): error: static assertion failed
      static_assert(decltype(size<1>(tTMEM_STORErS_x4) == _1{})::value );
      ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::C<64>, cute::C<64>>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 0ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::tuple<cute::tuple<cute::C<32>, cute::C<0>>, cute::C<0>>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::tuple<cute::tuple<cute::_0, int32_t>, cute::_2>, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<32>, 0>, cute::ScaledBasis<cute::C<1>, 1>>, cute::ScaledBasis<cute::C<32>, 1>>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(725): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=false, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 747
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(594): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_apply_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, need_apply_mask=true, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 763
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, Stage=int, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/fmha_fusion.hpp(129): warning #221-D: floating-point value does not fit in required floating-point type
          acc_qk(i) = -((float)(1e+300));
                        ^
          detected during:
            instantiation of "void cutlass::fmha::collective::ResidualMask::apply_mask(AccQK &, const IndexQK &, const ProblemSize &) [with AccQK=cute::Tensor<cute::ArrayEngine<float, 128ULL>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::_1, cute::_0>, cute::C<32>, cute::C<0>, cute::C<0>>>>, IndexQK=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<unsigned int, int>>>, cute::Layout<cute::tuple<cute::tuple<cute::_32, cute::_1>, cute::_4, cute::_1, cute::_1>, cute::tuple<cute::tuple<cute::ScaledBasis<cute::C<1>, 1>, cute::C<0>>, cute::ScaledBasis<cute::C<32>, 1>, cute::C<0>, cute::C<0>>>>, ProblemSize=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<cutlass::fmha::collective::VariableLength, cutlass::fmha::collective::VariableLength, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=true, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=true, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::false_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::true_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm120WorkstationConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(750): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max = -((float)(1e+300));
                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::true_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, TileScheduler=cutlass::fmha::kernel::PersistentTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(618): warning #221-D: floating-point value does not fit in required floating-point type
      ElementQK row_max_safe = row_max == -((float)(1e+300)) ? 0 : row_max;
                                            ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax_step<need_mask,Stage,BlkCoord,CoordTensor,ProblemShape>(__nv_bool, float &, float &, Stage, __nv_bool, const BlkCoord &, const CoordTensor &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::true_type, need_mask=true, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, CoordTensor=cute::Tensor<cute::ViewEngine<cute::ArithmeticTupleIterator<cute::ArithmeticTuple<int, int>>>, cute::Layout<cute::tuple<cute::_128, cute::_128>, cute::tuple<cute::ScaledBasis<cute::C<1>, 0>, cute::ScaledBasis<cute::C<1>, 1>>>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 774
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::softmax(Stage, const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineS &, cutlass::PipelineUmmaAsync<1, cute::Shape<cute::_1, cute::_1, cute::_1>>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineC &, cutlass::PipelineAsync<1>::PipelineState &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::OrderBarrierSoftmax &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::true_type, Stage=int, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>]" at line 481 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, TileScheduler=cutlass::fmha::kernel::PersistentTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_mla_fwd_mainloop_tma_warpspecialized.hpp(1165): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, ComposedTileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, ComposedTileShape_=flash::Sm100ServerConfig::TileShapeMlaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::true_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, TileScheduler=cutlass::fmha::kernel::PersistentTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, TileScheduler=cutlass::fmha::kernel::PersistentTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, cute::tuple<int32_t, int32_t>, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100MlaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeMlaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::true_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::true_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100MlaFwdCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(184): warning #550-D: variable "problem_size" was set but never used
      decltype(problem_shape_in) problem_size;
                                 ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=true, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=MlaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=true, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::true_type]" at line 93 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::CausalIndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::CausalIndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm120WorkstationConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm120WorkstationConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<unsigned int, cute::_0, cute::tuple<uint32_t, uint32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm120WorkstationConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::IndividualTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm120WorkstationConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm120WorkstationConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm120WorkstationConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::_64, cute::_128, cute::_64>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::IndividualTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 339 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm120WorkstationConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 42 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 335
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\collective/sm100_fmha_fwd_mainloop_tma_warpspecialized.hpp(1155): warning #221-D: floating-point value does not fit in required floating-point type
      float lse = -((float)(1e+300));
                    ^
          detected during:
            instantiation of "auto cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::correction_empty(const BlkCoord &, const cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::Params &, const ProblemShape &, const ParamsProblemShape &, TensorStorageEpi &, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<Element_, ElementQK_, ElementPV_, TileShape_, StrideQ_, StrideK_, StrideV_, Mask_, ThreadShape, OrderLoadEpilogue>::PipelineE &, cutlass::PipelineAsync<2>::PipelineState &, CollectiveEpilogue &) [with Element_=cutlass::bfloat16_t, ElementQK_=float, ElementPV_=float, TileShape_=flash::Sm100ServerConfig::TileShapeFmhaFwd, StrideQ_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, StrideK_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, StrideV_=cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, Mask_=cutlass::fmha::collective::ResidualMask, ThreadShape=flash::Sm100ServerConfig::ThreadShape, OrderLoadEpilogue=cute::false_type, BlkCoord=cute::tuple<int, cute::_0, cute::tuple<int32_t, int32_t>>, ProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, ParamsProblemShape=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, TensorStorageEpi=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>::TensorStorage, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>]" at line 511 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::PersistentTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\kernel/sm100_fmha_fwd_kernel_tma_warpspecialized.hpp(488): warning #550-D: variable "has_valid" was set but never used
        bool has_valid = false;
             ^
          detected during:
            instantiation of "void cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::operator()(const cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<KernelTraits_, ProblemShapeIn, CollectiveMainloop, CollectiveEpilogue, TileScheduler, KernelSchedule>::Params &, char *) [with KernelTraits_=flash::Sm100ServerConfig, ProblemShapeIn=cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, CollectiveMainloop=cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, CollectiveEpilogue=cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, TileScheduler=cutlass::fmha::kernel::PersistentTileScheduler, KernelSchedule=cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule]" at line 122 of C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/cutlass/include\cutlass/device_kernel.h
            instantiation of "void cutlass::device_kernel<Operator>(Operator::Params) [with Operator=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 176 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\device/fmha.hpp
            instantiation of "cutlass::Status cutlass::fmha::device::FMHA<Kernel_>::initialize(const cutlass::fmha::device::FMHA<Kernel_>::Arguments &, void *, cudaStream_t) [with Kernel_=cutlass::fmha::kernel::Sm100FmhaFwdKernelTmaWarpspecialized<flash::Sm100ServerConfig, cute::tuple<int, int, int, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cutlass::fmha::collective::Sm100FmhaFwdMainloopTmaWarpspecialized<cutlass::bfloat16_t, float, float, flash::Sm100ServerConfig::TileShapeFmhaFwd, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<cute::_0, int32_t>, int>>, cutlass::fmha::collective::ResidualMask, flash::Sm100ServerConfig::ThreadShape, cute::false_type>, cutlass::fmha::collective::Sm100FmhaFwdEpilogueTmaWarpspecialized<cutlass::bfloat16_t, float, cute::tuple<cute::C<128>, cute::C<128>, cute::C<128>>, cute::tuple<int, cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::tuple<cute::_1, cute::tuple<cute::tuple<int32_t, int32_t>, int>>, cute::false_type>, cutlass::fmha::kernel::PersistentTileScheduler, cutlass::fmha::kernel::Sm100FmhaCtxKernelWarpspecializedSchedule>]" at line 290 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=true, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 335 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cuh(196): warning #177-D: variable "get_head_dimension" was declared but never referenced
      auto get_head_dimension = [&]() {
           ^
          detected during:
            instantiation of "FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::ProblemShapeType FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::initialize(const Options &, int, int, int, int, void *, void *) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 242
            instantiation of "void FwdRunner<KernelTraits, kIsMla, kIsMaskTileSchedulerValid, kIsVarlen, Element_, ElementOut_, ActiveMask, KernelOptions...>::run(const Options &, const cutlass::KernelHardwareInfo &, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, at::Tensor, at::Tensor, at::Tensor, int, int) [with KernelTraits=flash::Sm100ServerConfig, kIsMla=false, kIsMaskTileSchedulerValid=false, kIsVarlen=false, Element_=cutlass::bfloat16_t, ElementOut_=cutlass::bfloat16_t, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>, Options=FmhaOptions]" at line 339
            instantiation of "void run_fmha_fwd<KernelTraits,DTypeIn,DTypeOut,kIsVarlen,kIsMla,ActiveMask,KernelOptions...>(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with KernelTraits=flash::Sm100ServerConfig, DTypeIn=cutlass::bfloat16_t, DTypeOut=cutlass::bfloat16_t, kIsVarlen=false, kIsMla=false, ActiveMask=cutlass::fmha::collective::ResidualMask, KernelOptions=<cutlass::fmha::kernel::Option<cutlass::fmha::kernel::Tag::kIsPersistent, cute::true_type>>]" at line 49 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu
            instantiation of "void call_run_fmha_fwd(Mask, Varlen, Element, ElementOut, Mla, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, float, int, int) [with Mask=cutlass::fmha::collective::ResidualMask, Varlen=cute::false_type, Element=cutlass::bfloat16_t, ElementOut=cutlass::bfloat16_t, Mla=cute::false_type]" at line 97 of C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\csrc\sm100\prefill\dense\fmha_cutlass_fwd_sm100.cu

51 errors detected in the compilation of "C:/PyCharmProjectsSpaceConflict/150BLLM/external/FlashMLA/csrc/sm100/prefill/dense/fmha_cutlass_fwd_sm100.cu".
ninja: build stopped: subcommand failed.
Traceback (most recent call last):
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\utils\cpp_extension.py", line 2597, in _run_ninja_build
    subprocess.run(
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 4294967295.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\PyCharmProjectsSpaceConflict\150BLLM\external\FlashMLA\setup.py", line 192, in <module>
    setup(
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\setuptools\__init__.py", line 115, in setup
    return distutils.core.setup(**attrs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\setuptools\_distutils\core.py", line 186, in setup
    return run_commands(dist)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\setuptools\_distutils\core.py", line 202, in run_commands
    dist.run_commands()
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\setuptools\_distutils\dist.py", line 1002, in run_commands
    self.run_command(cmd)
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\setuptools\dist.py", line 1102, in run_command
    super().run_command(command)
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\setuptools\_distutils\dist.py", line 1021, in run_command
    cmd_obj.run()
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\setuptools\command\build_ext.py", line 96, in run
    _build_ext.run(self)
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\setuptools\_distutils\command\build_ext.py", line 368, in run
    self.build_extensions()
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\utils\cpp_extension.py", line 1082, in build_extensions
    build_ext.build_extensions(self)
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\setuptools\_distutils\command\build_ext.py", line 484, in build_extensions
    self._build_extensions_serial()
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\setuptools\_distutils\command\build_ext.py", line 510, in _build_extensions_serial
    self.build_extension(ext)
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\setuptools\command\build_ext.py", line 261, in build_extension
    _build_ext.build_extension(self, ext)
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\setuptools\_distutils\command\build_ext.py", line 565, in build_extension
    objects = self.compiler.compile(
              ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\utils\cpp_extension.py", line 1051, in win_wrap_ninja_compile
    _write_ninja_file_and_compile_objects(
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\utils\cpp_extension.py", line 2223, in _write_ninja_file_and_compile_objects
    _run_ninja_build(
  File "C:\Users\Shashank Murthy\.conda\envs\150BLLM\Lib\site-packages\torch\utils\cpp_extension.py", line 2614, in _run_ninja_build
    raise RuntimeError(message) from e
RuntimeError: Error compiling objects for extension

Build complete. Check output for any errors.
